% Encoding: UTF-8

@Article{Innocente2019,
  author   = {Mauro S. Innocente and Paolo Grasso},
  journal  = {Journal of Computational Science},
  title    = {Self-organising swarms of firefighting drones: Harnessing the power of collective intelligence in decentralised multi-robot systems},
  year     = {2019},
  issn     = {1877-7503},
  pages    = {80 - 101},
  volume   = {34},
  abstract = {Swarm intelligence (SI) is concerned with the collective behaviour that emerges from decentralised self-organising systems, whilst swarm robotics (SR) is an approach to the self-coordination of large numbers of simple robots which emerged as the application of SI to multi-robot systems. Given the increasing severity and frequency of occurrence of wildfires and the hazardous nature of fighting their propagation, the use of disposable inexpensive robots in place of humans is of special interest. This paper demonstrates the feasibility and potential of employing SR to fight fires autonomously, with a focus on the self-coordination mechanisms for the desired firefighting behaviour to emerge. Thus, an efficient physics-based model of fire propagation and a self-organisation algorithm for swarms of firefighting drones are developed and coupled, with the collaborative behaviour based on a particle swarm algorithm adapted to individuals operating within physical dynamic environments of high severity and frequency of change. Numerical experiments demonstrate that the proposed self-organising system is effective, scalable and fault-tolerant, comprising a promising approach to dealing with the suppression of wildfires – one of the world's most pressing challenges of our time.},
  comment  = {Search Terms: robotics modelling and prediction system behaviour},
  doi      = {https://doi.org/10.1016/j.jocs.2019.04.009},
  file     = {:/home/sd/Documents/papers/innocente2019.pdf:PDF},
  keywords = {Self-organisation, Particle swarm, Fire spread modelling, Swarm robotics, Autonomous unmanned aerial vehicles},
  priority = {9},
  url      = {http://www.sciencedirect.com/science/article/pii/S1877750318310238},
}

@Article{Din2018,
  author   = {Ahmad Din and Meh Jabeen and Kashif Zia and Abbas Khalid and Dinesh Kumar Saini},
  journal  = {Computers \& Electrical Engineering},
  title    = {Behavior-based swarm robotic search and rescue using fuzzy controller},
  year     = {2018},
  issn     = {0045-7906},
  pages    = {53 - 65},
  volume   = {70},
  abstract = {Search and rescue (SAR) is one of the foremost issues in disaster management. A robust SAR mechanism can significantly reduce the number of causalities. This paper presents a behavior-based model for a swarm of small robots to perform an efficient SAR operation in an unknown environment. The swarm is guided by a dynamically selected virtual leader (VL). A self-contained dynamic goal-seeking mechanism, using behavior-based approach, is designed to search targets (victims). Under the leadership of VL, the proposed model retains the integrity of the swarm while driving it from its current position to referenced goals. Fuzzy logic has been used to design constituent behavioral modules, namely obstacle avoidance, alignment, and inter-robot cohesion. The model has been simulated to validate its efficiency and the findings reveal that robots moving as a swarm are more effective in the SAR process as compared to multiple single robots.},
  comment  = {Search Terms: robotics modelling and prediction system behaviour},
  doi      = {https://doi.org/10.1016/j.compeleceng.2018.06.003},
  file     = {:/home/sd/Documents/papers/din2018.pdf:PDF},
  keywords = {Behavior-based robotics, Swarm robotics, Search and rescue, Fuzzy controller, Virtual leader, Distributed search},
  priority = {6},
  url      = {http://www.sciencedirect.com/science/article/pii/S0045790618314216},
}

@Article{Khan2020,
  author   = {Md Mohiuddin Khan and Kathryn Kasmarik and Michael Barlow},
  journal  = {Swarm and Evolutionary Computation},
  title    = {Autonomous detection of collective behaviours in swarms},
  year     = {2020},
  issn     = {2210-6502},
  pages    = {100715},
  volume   = {57},
  abstract = {Collective behaviours such as swarm formations of autonomous agents offer the advantages of efficient movement, redundancy, and potential for human guidance of a single swarm organism. This paper proposes a developmental approach to evolving collective behaviours whereby the evolutionary process is guided by a novel value system. A self-organising map is used at the core of this value system and motion properties of the swarm entities are used as input. Unlike traditional approaches, this value system does not need in advance the precise characteristics of the intended behaviours. We examine the performance of this value system in a series of controlled experiments. Our results demonstrate that the value system can recognise multiple “interesting” structured collective behaviours and distinguish them from random movement patterns. Results show that our value system is most effective distinguishing structured behaviours from random behaviours when using motion properties of individual agents as input. Further variations and modifications to input data such as normalisation and aggregation were also investigated, and it was shown that certain configurations provide better results in distinguishing collective behaviours from random ones.},
  doi      = {https://doi.org/10.1016/j.swevo.2020.100715},
  file     = {:/home/sd/Documents/papers/khan2020.pdf:PDF},
  keywords = {Collective behaviour, Artificial swarming, Evolutionary framework, Boids model, Computational value systems},
  priority = {0},
  url      = {http://www.sciencedirect.com/science/article/pii/S2210650220303680},
}

@Article{Osaba2020,
  author   = {Eneko Osaba and Javier {Del Ser} and Andres Iglesias and Xin-She Yang},
  journal  = {Journal of Computational Science},
  title    = {Soft Computing for Swarm Robotics: New Trends and Applications},
  year     = {2020},
  issn     = {1877-7503},
  pages    = {101049},
  volume   = {39},
  abstract = {Robotics have experienced a meteoric growth over the last decades, reaching unprecedented levels of distributed intelligence and self-autonomy. Today, a myriad of real-world scenarios can benefit from the application of robots, such as structural health monitoring, complex manufacturing, efficient logistics or disaster management. Related to this topic, there is a paradigm connected to Swarm Intelligence which is grasping significant interest from the Computational Intelligence community. This branch of knowledge is known as Swarm Robotics, which refers to the development of tools and techniques to ease the coordination of multiple small-sized robots towards the accomplishment of difficult tasks or missions in a collaborative fashion. The success of Swarm Robotics applications comes from the efficient use of smart sensing, communication and organization functionalities endowed to these small robots, which allow for collaborative information sensing, operation and knowledge inference from the environment. The numerous industrial and social applications that can be addressed efficiently by virtue of swarm robotics unleashes a vibrant research area focused on distributing intelligence among autonomous agents with simple behavioral rules and communication schedules, yet potentially capable of realizing the most complex tasks. In this context, we present and overview recent contributions reported around this paradigm, which serves as an exemplary excerpt of the potential of Swarm Robotics to become a major research catalyst of the Computational Intelligence arena in years to come.},
  doi      = {https://doi.org/10.1016/j.jocs.2019.101049},
  file     = {:/home/sd/Documents/papers/osaba2019.pdf:PDF},
  keywords = {Swarm Robotics, Swarm Intelligence, Bio-inspired computation, Distributed Computing, Metaheuristics, Robotics},
  priority = {1},
  url      = {http://www.sciencedirect.com/science/article/pii/S187775031931172X},
}

@Article{Alshawi2017,
  author   = {Maha A. Alshawi and Mohamed B. Shalan},
  journal  = {International Journal of Mechanical Engineering and Robotics Research},
  title    = {Minimal Time Dynamic Task Allocation for a Swarm of Robots},
  year     = {2017},
  abstract = {This  paper  discusses  a  solution  to  one  of  the  key issues in the swarm robotics field which is the dynamic task allocation  problem  in  which  a group  of  robots  needs  to  be allocated to a set of tasks scattered in the environment in an efficient  and  decentralized  way.  The  application  considered in  this  context  is  the  foraging  application  which  can  be addressed  as  a  searching  job  followed  by  a  transportation job. The  near-optimal  allocation  scheme  is  found  by  using the  Particle  swarm  optimization  (PSO)  technique  to  handle the whole task execution in a minimal time. Two case studies have  been  considered using  different  swarm  sizes  and  the implemented   code   has   been   executed   for   a   distinctive number   of   iterations.   A   stability   proof   for   the   PSO technique’s  parameters  choices  is  presented.  Simulation results  were  verified  by  comparing  the  proposed  algorithm with   the   simulated   annealing   optimization   technique   in terms  of  computational  time,  number  of  iterations  needed and  quality  of  solution  to  demonstrate  the  robustness  and efficiency of the algorithm.},
  doi      = {10.18178/ijmerr.6.6.481-487},
  file     = {:/home/sd/Documents/papers/20171115061216427.pdf:PDF},
  keywords = {dynamic task allocation, swarm robotics, particle swarm optimization, simulated annealing, swarm optimization, homogeneous robots},
  priority = {0},
}

@Article{Winfield2008,
  author    = {Alan F. T. Winfield and Wenguo Liu and Julien Nembrini and Alcherio Martinoli},
  journal   = {Swarm Intelligence},
  title     = {Modelling a wireless connected swarm of mobile robots},
  year      = {2008},
  month     = {sep},
  number    = {2-4},
  pages     = {241--266},
  volume    = {2},
  doi       = {https://doi.org/10.1007/s11721-008-0018-0},
  file      = {:/home/sd/Documents/papers/Winfield2008_Article_ModellingAWirelessConnectedSwa.pdf:PDF},
  priority  = {39},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Vigelius2014,
  author    = {Vigelius, Matthias AND Meyer, Bernd AND Pascoe, Geoffrey},
  journal   = {PLOS ONE},
  title     = {Multiscale Modelling and Analysis of Collective Decision Making in Swarm Robotics},
  year      = {2014},
  month     = {11},
  number    = {11},
  pages     = {1-19},
  volume    = {9},
  abstract  = {We present a unified approach to describing certain types of collective decision making in swarm robotics that bridges from a microscopic individual-based description to aggregate properties. Our approach encompasses robot swarm experiments, microscopic and probabilistic macroscopic-discrete simulations as well as an analytic mathematical model. Following up on previous work, we identify the symmetry parameter, a measure of the progress of the swarm towards a decision, as a fundamental integrated swarm property and formulate its time evolution as a continuous-time Markov process. Contrary to previous work, which justified this approach only empirically and a posteriori, we justify it from first principles and derive hard limits on the parameter regime in which it is applicable.},
  doi       = {10.1371/journal.pone.0111542},
  file      = {:/home/sd/Documents/papers/journal.pone.0111542.PDF:PDF},
  priority  = {16},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pone.0111542},
}

@Article{Konur2012,
  author   = {Savas Konur and Clare Dixon and Michael Fisher},
  journal  = {Robotics and Autonomous Systems},
  title    = {Analysing robot swarm behaviour via probabilistic model checking},
  year     = {2012},
  issn     = {0921-8890},
  number   = {2},
  pages    = {199 - 213},
  volume   = {60},
  abstract = {An alternative to deploying a single robot of high complexity can be to utilise robot swarms comprising large numbers of identical, and much simpler, robots. Such swarms have been shown to be adaptable, fault-tolerant and widely applicable. However, designing individual robot algorithms to ensure effective and correct overall swarm behaviour is actually very difficult. While mechanisms for assessing the effectiveness of any swarm algorithm before deployment are essential, such mechanisms have traditionally involved either computational simulations of swarm behaviour, or experiments with robot swarms themselves. However, such simulations or experiments cannot, by their nature, analyse all possible swarm behaviours. In this paper, we will develop and apply the use of automated probabilistic formal verification techniques to robot swarms, involving an exhaustive mathematical analysis, in order to assess whether swarms will indeed behave as required. In particular we consider a foraging robot scenario to which we apply probabilistic model checking.},
  doi      = {https://doi.org/10.1016/j.robot.2011.10.005},
  file     = {:/home/sd/Documents/papers/1-s2.0-S0921889011001916-main.pdf:PDF},
  keywords = {Robot swarms, Swarm algorithms, Formal verification, Probabilistic model-checking},
  priority = {62},
  url      = {http://www.sciencedirect.com/science/article/pii/S0921889011001916},
}

@Article{Mirzaei2020,
  author    = {Faezeh Mirzaei and Ali Akbar Pouyan and Mohsen Biglari},
  journal   = {Journal of Intelligent {\&} Robotic Systems},
  title     = {Automatic Controller Code Generation for Swarm Robotics Using Probabilistic Timed Supervisory Control Theory ({ptSCT})},
  year      = {2020},
  month     = {sep},
  number    = {2},
  pages     = {729--750},
  volume    = {100},
  doi       = {https://doi.org/10.1007/s10846-020-01201-4},
  file      = {:/home/sd/Documents/papers/Mirzaei2020_Article_AutomaticControllerCodeGenerat.pdf:PDF},
  priority  = {0},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Chung2018,
  author   = {S. {Chung} and A. A. {Paranjape} and P. {Dames} and S. {Shen} and V. {Kumar}},
  journal  = {IEEE Transactions on Robotics},
  title    = {A Survey on Aerial Swarm Robotics},
  year     = {2018},
  issn     = {1941-0468},
  month    = {Aug},
  number   = {4},
  pages    = {837-855},
  volume   = {34},
  abstract = {The use of aerial swarms to solve real-world problems has been increasing steadily, accompanied by falling prices and improving performance of communication, sensing, and processing hardware. The commoditization of hardware has reduced unit costs, thereby lowering the barriers to entry to the field of aerial swarm robotics. A key enabling technology for swarms is the family of algorithms that allow the individual members of the swarm to communicate and allocate tasks amongst themselves, plan their trajectories, and coordinate their flight in such a way that the overall objectives of the swarm are achieved efficiently. These algorithms, often organized in a hierarchical fashion, endow the swarm with autonomy at every level, and the role of a human operator can be reduced, in principle, to interactions at a higher level without direct intervention. This technology depends on the clever and innovative application of theoretical tools from control and estimation. This paper reviews the state of the art of these theoretical tools, specifically focusing on how they have been developed for, and applied to, aerial swarms. Aerial swarms differ from swarms of ground-based vehicles in two respects: they operate in a three-dimensional space and the dynamics of individual vehicles adds an extra layer of complexity. We review dynamic modeling and conditions for stability and controllability that are essential in order to achieve cooperative flight and distributed sensing. The main sections of this paper focus on major results covering trajectory generation, task allocation, adversarial control, distributed sensing, monitoring, and mapping. Wherever possible, we indicate how the physics and subsystem technologies of aerial robots are brought to bear on these individual areas.},
  doi      = {10.1109/TRO.2018.2857475},
  file     = {:/home/sd/Documents/papers/08424838.pdf:PDF},
  keywords = {autonomous aerial vehicles;controllability;cooperative systems;distributed sensors;mobile robots;multi-robot systems;stability;trajectory control;human operator;clever application;innovative application;ground-based vehicles;three-dimensional space;individual vehicles dynamics;cooperative flight;trajectory generation;distributed sensing;task allocation;adversarial control;distributed monitoring;distributed mapping;stability;controllability;theoretical tools;aerial swarm robotics;Robot kinematics;Robot sensing systems;Unmanned aerial vehicles;Vehicle dynamics;Mathematical model;Planning;Aerial robotics;distributed robot systems;networked robots},
  priority = {33},
}

@Article{Mavrovouniotis2017,
  author   = {Michalis Mavrovouniotis and Changhe Li and Shengxiang Yang},
  journal  = {Swarm and Evolutionary Computation},
  title    = {A survey of swarm intelligence for dynamic optimization: Algorithms and applications},
  year     = {2017},
  issn     = {2210-6502},
  pages    = {1 - 17},
  volume   = {33},
  abstract = {Swarm intelligence (SI) algorithms, including ant colony optimization, particle swarm optimization, bee-inspired algorithms, bacterial foraging optimization, firefly algorithms, fish swarm optimization and many more, have been proven to be good methods to address difficult optimization problems under stationary environments. Most SI algorithms have been developed to address stationary optimization problems and hence, they can converge on the (near-) optimum solution efficiently. However, many real-world problems have a dynamic environment that changes over time. For such dynamic optimization problems (DOPs), it is difficult for a conventional SI algorithm to track the changing optimum once the algorithm has converged on a solution. In the last two decades, there has been a growing interest of addressing DOPs using SI algorithms due to their adaptation capabilities. This paper presents a broad review on SI dynamic optimization (SIDO) focused on several classes of problems, such as discrete, continuous, constrained, multi-objective and classification problems, and real-world applications. In addition, this paper focuses on the enhancement strategies integrated in SI algorithms to address dynamic changes, the performance measurements and benchmark generators used in SIDO. Finally, some considerations about future directions in the subject are given.},
  doi      = {https://doi.org/10.1016/j.swevo.2016.12.005},
  file     = {:/home/sd/Documents/papers/mavrovouniotis2017.pdf:PDF},
  keywords = {Swarm intelligence, Dynamic optimization, Ant colony optimization, Particle swarm optimization},
  priority = {189},
  url      = {http://www.sciencedirect.com/science/article/pii/S2210650216302541},
}

@Article{Derrac2011,
  author   = {Joaquín Derrac and Salvador García and Daniel Molina and Francisco Herrera},
  journal  = {Swarm and Evolutionary Computation},
  title    = {A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms},
  year     = {2011},
  issn     = {2210-6502},
  number   = {1},
  pages    = {3 - 18},
  volume   = {1},
  abstract = {The interest in nonparametric statistical analysis has grown recently in the field of computational intelligence. In many experimental studies, the lack of the required properties for a proper application of parametric procedures–independence, normality, and homoscedasticity–yields to nonparametric ones the task of performing a rigorous comparison among algorithms. In this paper, we will discuss the basics and give a survey of a complete set of nonparametric procedures developed to perform both pairwise and multiple comparisons, for multi-problem analysis. The test problems of the CEC’2005 special session on real parameter optimization will help to illustrate the use of the tests throughout this tutorial, analyzing the results of a set of well-known evolutionary and swarm intelligence algorithms. This tutorial is concluded with a compilation of considerations and recommendations, which will guide practitioners when using these tests to contrast their experimental results.},
  doi      = {https://doi.org/10.1016/j.swevo.2011.02.002},
  file     = {:/home/sd/Documents/papers/1-s2.0-S2210650211000034-main.pdf:PDF},
  keywords = {Statistical analysis, Nonparametric statistics, Pairwise comparisons, Multiple comparisons, Evolutionary algorithms, Swarm intelligence algorithms},
  priority = {21},
  url      = {http://www.sciencedirect.com/science/article/pii/S2210650211000034},
}

@Article{Lynn2015,
  author   = {Nandar Lynn and Ponnuthurai Nagaratnam Suganthan},
  journal  = {Swarm and Evolutionary Computation},
  title    = {Heterogeneous comprehensive learning particle swarm optimization with enhanced exploration and exploitation},
  year     = {2015},
  issn     = {2210-6502},
  pages    = {11 - 24},
  volume   = {24},
  abstract = {This paper presents a comprehensive learning particle swarm optimization algorithm with enhanced exploration and exploitation, named as “heterogeneous comprehensive learning particle swarm optimization” (HCLPSO). In this algorithm, the swarm population is divided into two subpopulations. Each subpopulation is assigned to focus solely on either exploration or exploitation. Comprehensive learning (CL) strategy is used to generate the exemplars for both subpopulations. In the exploration-subpopulation, the exemplars are generated by using personal best experiences of the particles in the exploration-subpopulation itself. In the exploitation-subpopulation, the personal best experiences of the entire swarm population are used to generate the exemplars. As the exploration-subpopulation does not learn from any particles in the exploitation-subpopulation, the diversity in the exploration-subpopulation can be retained even if the exploitation-subpopulation converges prematurely. The heterogeneous comprehensive learning particle swarm optimization algorithm is tested on shifted and rotated benchmark problems and compared with other recent particle swarm optimization algorithms to demonstrate superior performance of the proposed algorithm over other particle swarm optimization variants.},
  doi      = {https://doi.org/10.1016/j.swevo.2015.05.002},
  file     = {:/home/sd/Documents/papers/1-s2.0-S2210650215000401-main.pdf:PDF},
  keywords = {Comprehensive learning (CL), Exploration, Exploitation, Particle swarm optimization (PSO), Heterogeneous},
  printed  = {171},
  url      = {http://www.sciencedirect.com/science/article/pii/S2210650215000401},
}
{Shi2012,
  author    = {Shi, Zhiguo and Tu, Jun and Zhang, Qiao and Liu, Lei and Wei, Junming},
  booktitle = {Advances in Swarm Intelligence},
  title     = {A Survey of Swarm Robotics System},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  editor    = {Tan, Ying and Shi, Yuhui and Ji, Zhen},
  pages     = {564--572},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Swarm robotics system has been a particularly active topic of robotics in recent years due to the increasing deepening of research on robotics technology and application. This paper gives a survey of swarm robotics system research from such aspects as theoretical basis and physical research, simulation platform, distributed control information fusion and communications system. Some problems that need to be solved about swarm robotics system research in IOT (Internet of Things) environment are also raised, such as co-adaptation, distributed control and self-organization, resource scheduling management. Finally, the ant colony algorithm and particle swarm optimization are applied to the swarm robotics system.},
  doi       = {https://doi.org/10.1007/978-3-642-30976-2_68\},
  file      = {:/home/sd/Documents/papers/2012_Book_AdvancesInSwarmIntelligence.pdf:PDF},
  isbn      = {978-3-642-30976-2},
  priority  = {16},
}

@Article{Miner2007,
  author    = {Miner, Don},
  journal   = {Report, MAPLE lab, University of Maryland},
  title     = {Swarm robotics algorithms: A survey},
  year      = {2007},
  doi       = {10.1.1.99.4450},
  file      = {:/home/sd/Documents/papers/10.1.1.99.4450.pdf:PDF},
  priority  = {2},
  publisher = {Citeseer},
}

@InProceedings{Schneider2003,
  author    = {F. E. {Schneider} and D. {Wildermuth}},
  booktitle = {IEEE International Conference on Robotics, Intelligent Systems and Signal Processing, 2003. Proceedings. 2003},
  title     = {A potential field based approach to multi robot formation navigation},
  year      = {2003},
  month     = {Oct},
  pages     = {680-685 vol.1},
  volume    = {1},
  abstract  = {This paper presents a directed potential field approach for motion co-ordination in formations of multi-robot-systems. First a short introduction to the application of MRS formation navigation is given. The approach is briefly compared to related work. For the sub-task of moving in formation, a solution based on a potential field approach is presented. Different forces belonging to other robots, obstacles and the aspired shape of formation are combined and used to move each robot to its desired position inside the formation. While moving in formation, the group is able to avoid obstacles and approach towards a specified target. First results in simulation and with real robots in the presence of obstacles are presented.},
  doi       = {10.1109/RISSP.2003.1285656},
  file      = {:/home/sd/Documents/papers/01285656.pdf:PDF},
  keywords  = {multi-robot systems;mobile robots;navigation;collision avoidance;multirobot formation navigation;multirobot-systems;directed potential field;motion coordination;obstacle avoidance;Navigation;Shape;Robot sensing systems;Orbital robotics;Mobile robots;Communication networks;Decontamination;Waste management;Agriculture;Surveillance},
  priority  = {46},
}

@InProceedings{Liang2014,
  author    = {J. {Liang} and C. {Lee}},
  booktitle = {11th IEEE International Conference on Control Automation (ICCA)},
  title     = {Self-navigation of multi-robot system using artificial bee colony algorithm},
  year      = {2014},
  month     = {June},
  pages     = {243-248},
  abstract  = {Based on the artificial bee colony (ABC) algorithm, this paper proposes a novel design approach for self-navigation of a multi-robot system. To treat the self-navigation (or on-line path planning) of multi-robot system, the hybrid objective functions for target, obstacles, and robots collision avoidance are selected. By the ABC algorithm, the next positions of each robot are designed and then, the tracking control to the planned neighborhood target is done by the PID controllers. Thus, the mobiles robots can travel to the target without collision. Finally, simulation results are introduced to show the effectiveness and performance of the proposed approach.},
  doi       = {10.1109/ICCA.2014.6870927},
  file      = {:/home/sd/Documents/papers/06870927.pdf:PDF},
  issn      = {1948-3457},
  keywords  = {collision avoidance;control system synthesis;evolutionary computation;mobile robots;multi-robot systems;navigation;three-term control;tracking;self-navigation;multirobot system;artificial bee colony algorithm;ABC algorithm;on-line path planning;hybrid objective functions;robot collision avoidance;tracking control;planned neighborhood target;PID controllers;Collision avoidance;Sociology;Statistics;Mobile robots;Linear programming;Multi-robot systems},
  priority  = {0},
}

@InProceedings{Liu2006,
  author    = {S. {Liu} and L. {Mao} and J. {Yu}},
  booktitle = {2006 International Conference on Mechatronics and Automation},
  title     = {Path Planning Based on Ant Colony Algorithm and Distributed Local Navigation for Multi-Robot Systems},
  year      = {2006},
  month     = {June},
  pages     = {1733-1738},
  abstract  = {This paper presents a decoupled path planning based on ant colony algorithm and distributed navigation with collision avoidance for multi-robot systems. An improved ant colony algorithm is proposed to plan a reasonable collision-free path for each mobile robot of multi-robot system in the decoupled path planning scheme in complicated static environment. The special functions are added into the regular ant colony algorithm to improve the selective strategy. When an ant explores a dead-corner in path searching, a dead-corner table is established and a penalty function is used for the trail intensity updated in order to avoid the path deadlock of mobile robot. A behavior strategy on "first come and first service" is adopted to solve the conflict between moving robots in distributed local navigation. Simulation results show that the proposed method can effectively improve the performance of the planned path, and the individual robots with collision-free can achieve to reach their goal locations by the simple local navigation strategies},
  doi       = {10.1109/ICMA.2006.257476},
  file      = {:/home/sd/Documents/papers/04026354.pdf:PDF},
  issn      = {2152-744X},
  keywords  = {collision avoidance;cooperative systems;mobile robots;multi-robot systems;ant colony algorithm;distributed local navigation;multi-robot systems;collision avoidance;collision-free path;mobile robot;decoupled path planning;path searching;Path planning;Navigation;Multirobot systems;Robot kinematics;Mobile robots;Collision avoidance;Robotics and automation;Robot sensing systems;Orbital robotics;Motion planning;Multiple mobile robots;ant colony algorithm;path planning;distributed navigation},
  priority  = {22},
}

@Article{Roldan2016,
  author    = {Juan Rold{\'{a}}n and Pablo Garcia-Aunon and Mario Garz{\'{o}}n and Jorge de Le{\'{o}}n and Jaime del Cerro and Antonio Barrientos},
  journal   = {Sensors},
  title     = {Heterogeneous Multi-Robot System for Mapping Environmental Variables of Greenhouses},
  year      = {2016},
  month     = {jul},
  number    = {7},
  pages     = {1018},
  volume    = {16},
  doi       = {https://doi.org/10.3390/s16071018},
  file      = {:/home/sd/Documents/papers/sensors-16-01018.pdf:PDF},
  keywords  = {rank3},
  publisher = {{MDPI} {AG}},
  ranking   = {rank3},
}

@Article{Ball2015,
  author    = {David Ball and Patrick Ross and Andrew English and Tim Patten and Ben Upcroft and Robert Fitch and Salah Sukkarieh and Gordon Wyeth and Peter Corke},
  title     = {Robotics for Sustainable Broad-Acre Agriculture},
  year      = {2015},
  pages     = {439--453},
  booktitle = {Springer Tracts in Advanced Robotics},
  doi       = {https://doi.org/10.1007/978-3-319-07488-7_30},
  file      = {:/home/sd/Documents/papers/2015_Book_FieldAndServiceRobotics.pdf:PDF},
  priority  = {16},
  publisher = {Springer International Publishing},
}

@Article{Gao2018,
  author    = {Tianshuang Gao and Hamid Emadi and Homagni Saha and Jiaoping Zhang and Alec Lofquist and Arti Singh and Baskar Ganapathysubramanian and Soumik Sarkar and Asheesh Singh and Sourabh Bhattacharya},
  journal   = {Robotics},
  title     = {A Novel Multirobot System for Plant Phenotyping},
  year      = {2018},
  month     = {sep},
  number    = {4},
  pages     = {61},
  volume    = {7},
  doi       = {https://doi.org/10.3390/robotics7040061},
  file      = {:/home/sd/Documents/papers/robotics-07-00061.pdf:PDF},
  priority  = {6},
  publisher = {{MDPI} {AG}},
}

@InProceedings{Hameed2018,
  author    = {I. A. {Hameed}},
  booktitle = {2018 IEEE International Conference on Real-time Computing and Robotics (RCAR)},
  title     = {A Coverage Planner for Multi-Robot Systems in Agriculture},
  year      = {2018},
  month     = {Aug},
  pages     = {698-704},
  abstract  = {Driving heavy tractors and agricultural machinery on soil for growing plants causes more permanent damage to the soil than was previously believed. Compacting the soil severely deteriorates soil fertility leading to poor crop yields and increased population from agricultural lands. In addition, compacted soils require many years of expensive treatment to recover their fertility. Soil compaction problem can be solved by replacing heavy tractors and machinery with a number of smaller and lighter vehicles that is capable of treating crop fields as well as heavy ones without compacting the soil. However, this scenario is impractical because of the high operating cost to secure a human operator/driver for each vehicle. A practical solution is to replace heavy tractors and machinery by a set of autonomous vehicles that require minimum or no human intervention. In this paper, the technology required to enable a single farmer to supervise and operate a team of automated vehicles, is proposed. This will include the development of a Mission Control Center and Intelligent Coverage Path Planning algorithms to enable team/swarm of autonomous vehicles to communicate and cooperate and solve a range of agricultural tasks in a safe and efficient way.},
  doi       = {10.1109/RCAR.2018.8621801},
  file      = {:/home/sd/Documents/papers/08621801.pdf:PDF},
  keywords  = {agricultural machinery;crops;fertilisers;industrial robots;mobile robots;multi-robot systems;path planning;soil;autonomous vehicles;automated vehicles;Intelligent Coverage Path Planning algorithms;multirobot systems;heavy tractors;agricultural machinery;soil fertility;soil compaction problem;Robots;Soil;Agriculture;Interpolation;Task analysis;Agricultural machinery;Surface topography;multi-robot planning;cooperative navigation;optimization;agriculture},
  priority  = {0},
}

@Article{CORTES2017,
  author    = {Jorge CORT{\'{E}}S and Magnus EGERSTEDT},
  journal   = {{SICE} Journal of Control, Measurement, and System Integration},
  title     = {Coordinated Control of Multi-Robot Systems: A Survey},
  year      = {2017},
  number    = {6},
  pages     = {495--503},
  volume    = {10},
  doi       = {https://doi.org/10.9746/jcmsi.10.495},
  file      = {:/home/sd/Documents/papers/10_495.pdf:PDF},
  priority  = {12},
  publisher = {The Society of Instrument and Control Engineers},
}

@Article{Ni2020,
  author   = {J. {Ni} and X. {Wang} and M. {Tang} and W. {Cao} and P. {Shi} and S. X. {Yang}},
  journal  = {IEEE Access},
  title    = {An Improved Real-Time Path Planning Method Based on Dragonfly Algorithm for Heterogeneous Multi-Robot System},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {140558-140568},
  volume   = {8},
  abstract = {Heterogeneous multi-robot system is one of the most important research directions in the robotic field. Real-time path planning for heterogeneous multi-robot system under unknown 3D environment is a new challenging research and a hot spot in this field. In this paper, an improved real-time path planning method is proposed for a heterogeneous multi-robot system, which is composed of many unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). In the proposed method, the 3D environment is modelled as a neuron topology map, based on the grid method combined with the bio-inspired neural network. Then a new 3D dynamic movement model for multi-robots is established based on an improved Dragonfly Algorithm (DA). Thus, the movements of the robots are optimized according to the activities of the neurons in the bio-inspired neural network to realize the real-time path planning. Furthermore, some simulations have been carried out. The results show that the proposed method can effectively guide the heterogeneous UAV/UGV system to the target, and has better performance than traditional methods in the real-time path planning tasks.},
  doi      = {10.1109/ACCESS.2020.3012886},
  file     = {:/home/sd/Documents/papers/09152817.pdf:PDF},
  keywords = {autonomous aerial vehicles;mobile robots;multi-robot systems;neurocontrollers;path planning;UAV/UGV system;bio-inspired neural network;grid method;neuron topology map;3D environment;dragonfly algorithm;real-time path planning method;heterogeneous multirobot system;multirobots;unmanned ground vehicles;Path planning;Real-time systems;Three-dimensional displays;Robots;Multi-robot systems;Neurons;Task analysis;Heterogeneous multi-robot system;path planning;dragonfly algorithm;bio-inspired neural network},
  priority = {0},
}

@Article{Bechar2016,
  author   = {Avital Bechar and Clément Vigneault},
  journal  = {Biosystems Engineering},
  title    = {Agricultural robots for field operations: Concepts and components},
  year     = {2016},
  issn     = {1537-5110},
  pages    = {94 - 111},
  volume   = {149},
  abstract = {This review investigates the research effort, developments and innovation in agricultural robots for field operations, and the associated concepts, principles, limitations and gaps. Robots are highly complex, consisting of different sub-systems that need to be integrated and correctly synchronised to perform tasks perfectly as a whole and successfully transfer the required information. Extensive research has been conducted on the application of robots and automation to a variety of field operations, and technical feasibility has been widely demonstrated. Agricultural robots for field operations must be able to operate in unstructured agricultural environments with the same quality of work achieved by current methods and means. To assimilate robotic systems, technologies must be developed to overcome continuously changing conditions and variability in produce and environments. Intelligent systems are needed for successful task performance in such environments. The robotic system must be cost-effective, while being inherently safe and reliable—human safety, and preservation of the environment, the crop and the machinery are mandatory. Despite much progress in recent years, in most cases the technology is not yet commercially available. Information-acquisition systems, including sensors, fusion algorithms and data analysis, need to be adjusted to the dynamic conditions of unstructured agricultural environments. Intensive research is needed on integrating human operators into the system control loop for increased system performance and reliability. System sizes should be reduced while improving the integration of all parts and components. For robots to perform in agricultural environments and execute agricultural tasks, research must focus on: fusing complementary sensors for adequate localisation and sensing abilities, developing simple manipulators for each agricultural task, developing path planning, navigation and guidance algorithms suited to environments besides open fields and known a-priori, and integrating human operators in this complex and highly dynamic situation.},
  comment  = {The main subject of this paper is to show the current development, ideas and problems in the field of agricultural 
robotics. This review paper explains first the background, then the economic feasibility and furthers goes into 
concepts, principles and components.

The paper concludes, that with current technologies the broad usage in commercial farming is not possible yet and 
proposes to focus research on a number of fields. Those fields include sensor fusion for better localisation, 
engineering of better simple manipulators and the development of specific path planning, navigation and guidance algorithms
for agriculture.

The authors make a great job in displaying the current technologies and their limitations. With this knowledge it is 
easy to identify a subproblem to work on.
Several points come to the mind. Firstly they create an in-depth background needed to understand the need of automated
systems in agriculture, but also explain why it is so hard to create such systems. 
They propose a categorization of robotic system after the structure of their environment and object of interest. Both 
can be either structured or unstructured. This categorization creates four different categories. First, a structured 
environment and a structured object: This is the industrial domain. Second, a strucutred environment and a unstructured
object: the medial domain. Further there is the unstructured enviroment with a structured object: the military, space, underwater
and mining domains. The last domain, unstructured in environment and object of interest is the agricultural domain.

The next contribution are guidelines under which circumstances a robot can be commercially successful. These guideline conclude
that it is possible to start using robots even if the costs are the same as conventional methods if the work of
the robots create more steady and predictable processes.

A big part of the review are categorization concepts, components and principles. These include Human-Robot-Systems versus
Autonomous Robot Systems. In the component section the authors underline following topics: steering and mobility, 
sensing and self-localization, path planning and guidance and last but not least, manipulators and effectors.

One of the main problems is the highly dynamic environment and the need to react fast to unprecedented situations.
This creates the question on how to define behavior in such a way to allow and strengthen the capabilities of 
improvisation.

Summary: In-depth review paper with some self citations but besides that it gives many new points to deepen my reseach.},
  doi      = {https://doi.org/10.1016/j.biosystemseng.2016.06.014},
  file     = {:/home/sd/Documents/papers/1-s2.0-S1537511015301914-main.pdf:PDF},
  keywords = {Agricultural robots, Robotics, Field operations, Autonomous, rank5},
  ranking  = {rank5},
  url      = {http://www.sciencedirect.com/science/article/pii/S1537511015301914},
}

@Article{Huang2020,
  author   = {Zichen Huang and Tsay L.W. Jacky and Xunyue Zhao and Hiroki Fukuda and Tomoo Shiigi and Hiroaki Nakanishi and Tetsuhito Suzuki and Yuichi Ogawa and Naoshi Kondo},
  journal  = {Biosystems Engineering},
  title    = {Position and orientation measurement system using spread spectrum sound for greenhouse robots},
  year     = {2020},
  issn     = {1537-5110},
  pages    = {50 - 62},
  volume   = {198},
  abstract = {Position and orientation data are critical for guiding and managing cooperative robot tasks in the greenhouse. Errors, however, associated with current positioning and orientation systems, such as indoor GPS compasses or the sensitivity of magnetic direction sensors to magnetic materials, limit their application in greenhouses. In this research, we develop and evaluate a positioning and orientation system using a sound signal and two different receiver architectures in a greenhouse. The results obtained: a positioning accuracy of 23.0 ± 5.5 mm and average orientation accuracy of 3.43 ± 1.67° and 1.58 ± 0.86° for these two methods, demonstrate this spread spectrum sound based system has the potential to be deployed on small distributed greenhouse robots.},
  doi      = {https://doi.org/10.1016/j.biosystemseng.2020.07.006},
  file     = {:/home/sd/Documents/papers/huang2020.pdf:PDF},
  keywords = {Spread Spectrum Sound, Positioning System, Orientation measurement},
  priority = {0},
  url      = {http://www.sciencedirect.com/science/article/pii/S1537511020301999},
}

@Article{Tiwari2020,
  author    = {Arti Tiwari and Micha Silver and Arnon Karnieli},
  journal   = {Biosystems Engineering},
  title     = {Developing object-based image procedures for classifying and characterising different protected agriculture structures using {LiDAR} and orthophoto},
  year      = {2020},
  month     = {oct},
  pages     = {91--104},
  volume    = {198},
  doi       = {10.1016/j.biosystemseng.2020.07.017},
  file      = {:/home/sd/Documents/papers/tiwari2020.pdf:PDF},
  priority  = {0},
  publisher = {Elsevier {BV}},
}

@Article{Ge2020,
  author    = {Yuanyue Ge and Ya Xiong and P{\aa}l J. From},
  journal   = {Biosystems Engineering},
  title     = {Symmetry-based 3D shape completion for fruit localisation for harvesting robots},
  year      = {2020},
  month     = {sep},
  pages     = {188--202},
  volume    = {197},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2020.07.003},
  file      = {:/home/sd/Documents/papers/ge2020.pdf:PDF},
  priority  = {0},
  publisher = {Elsevier {BV}},
}

@Article{Fu2020,
  author    = {Longsheng Fu and Yaqoob Majeed and Xin Zhang and Manoj Karkee and Qin Zhang},
  journal   = {Biosystems Engineering},
  title     = {Faster R{\textendash}{CNN}{\textendash}based apple detection in dense-foliage fruiting-wall trees using {RGB} and depth features for robotic harvesting},
  year      = {2020},
  month     = {sep},
  pages     = {245--256},
  volume    = {197},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2020.07.007},
  file      = {:/home/sd/Documents/papers/10.1016@j.biosystemseng.2020.07.007.pdf:PDF},
  priority  = {5},
  publisher = {Elsevier {BV}},
}

@Article{Chen2020,
  author    = {Cheng Chen and Bo Li and Jiaxiang Liu and Tong Bao and Ni Ren},
  journal   = {Biosystems Engineering},
  title     = {Monocular positioning of sweet peppers: An instance segmentation approach for harvest robots},
  year      = {2020},
  month     = {aug},
  pages     = {15--28},
  volume    = {196},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2020.05.005},
  file      = {:/home/sd/Documents/papers/chen2020.pdf:PDF},
  priority  = {0},
  publisher = {Elsevier {BV}},
}

@Article{Raja2020,
  author    = {Rekha Raja and Thuy T. Nguyen and Vivian L. Vuong and David C. Slaughter and Steven A. Fennimore},
  journal   = {Biosystems Engineering},
  title     = {{RTD}-{SEPs}: Real-time detection of stem emerging points and classification of crop-weed for robotic weed control in producing tomato},
  year      = {2020},
  month     = {jul},
  pages     = {152--171},
  volume    = {195},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2020.05.004},
  file      = {:/home/sd/Documents/papers/raja2020.pdf:PDF},
  priority  = {0},
  publisher = {Elsevier {BV}},
}

@Article{Herck2020,
  author    = {Liesbet van Herck and Polina Kurtser and Lieve Wittemans and Yael Edan},
  journal   = {Biosystems Engineering},
  title     = {Crop design for improved robotic harvesting: A case study of sweet pepper harvesting},
  year      = {2020},
  month     = {apr},
  pages     = {294--308},
  volume    = {192},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2020.01.021},
  file      = {:/home/sd/Documents/papers/vanherck2020.pdf:PDF},
  keywords  = {rank5},
  publisher = {Elsevier {BV}},
  ranking   = {rank5},
}

@Article{VillaHenriksen2020,
  author    = {Andr{\'{e}}s Villa-Henriksen and Gareth T.C. Edwards and Liisa A. Pesonen and Ole Green and Claus Aage Gr{\o}n S{\o}rensen},
  journal   = {Biosystems Engineering},
  title     = {Internet of Things in arable farming: Implementation, applications, challenges and potential},
  year      = {2020},
  month     = {mar},
  pages     = {60--84},
  volume    = {191},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2019.12.013},
  file      = {:/home/sd/Documents/papers/villa-henriksen2020.pdf:PDF},
  priority  = {13},
  publisher = {Elsevier {BV}},
}

@Article{Oberti2016,
  author    = {R. Oberti and A. Shapiro},
  journal   = {Biosystems Engineering},
  title     = {Advances in robotic agriculture for crops},
  year      = {2016},
  month     = {jun},
  pages     = {1--2},
  volume    = {146},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2016.05.010},
  file      = {:/home/sd/Documents/papers/oberti2016.pdf:PDF},
  priority  = {12},
  publisher = {Elsevier {BV}},
}

@Article{Pedersen2006,
  author    = {S. M. Pedersen and S. Fountas and H. Have and B. S. Blackmore},
  journal   = {Precision Agriculture},
  title     = {Agricultural robots{\textemdash}system analysis and economic feasibility},
  year      = {2006},
  month     = {jul},
  number    = {4},
  pages     = {295--308},
  volume    = {7},
  abstract  = {This paper focuses on the economic feasibility of applying autonomous roboticvehicles compared to conventional systems in three different applications: roboticweeding in high value crops (particularly sugar beet), crop scouting in cerealsand  grass  cutting  on  golf  courses.   The  comparison  was  based  on  a  systemsanalysis and an individual economic feasibility study for each of the three appli-cations.  The results showed that in all three scenarios, the robotic applicationsare more economically feasible than the conventional systems.  The high costof real time kinematics Global Positioning System (RTK-GPS) and the smallcapacity of the vehicles are the main parameters that increase the cost of therobotic systems.},
  comment   = {The papers main focus lies on displaying the cost reduction possible by utilizingautonomous system for agriculture tasks.  Most agricultural task can not useindividual-plant-based  solutions  with  conventional  methods.   By  using  robotsand big data processing it will be possible to care for each plant individually.Taking care of an identified weed patch for example will need much less herbi-cides than spaying the whole field preemptively.
The authors propose solutions for using autonomous robots for field scouting -the identification and localisation of growing weeds -, intra-row and near-cropweeding and automated grass cutting.
In all scenarios the authors showcase a reduction in primary and secondary costsin comparison to conventional methods.

Field scouting:20% cost reduction in labor and secondary benefits of the databecause it is now possible to only deploy herbicides where needed.
Weeding:Only  by  reducing  the  cost  of  the  navigation  system  by  half  it  ispossible to save 12-21% or manuel costs.  and reduction of herbicide useof 90%.
Grass cutting:Reduction of cost of 52% (but only when paying the gardener27 Euro per hour, lol)

The usage of automated systems for growing crops is one of the key points inreducing the environmental footprint of large scale agriculture.  The three ana-lyzed areas are great entry points for deploying such systems. Especially the fieldscouting and the automated weeding are very interesting.  For the evaluationthe authors compared the costs of the components with average conventionalcosts witch is mostly reasonable, expect the estimated labor cost of the gardenerof 27 Euros per hour for grass cutting.

The ideas of the authors in breaking down the cost of the robots into severalcomponents are very helpful to estimate economic costs of different system forthis  usage.   The  main  contribution  is  this  economic  analysis  which  helped  tospark more research in this direction.

There will always be economic analyses for newer technology. Because  this  paper  is  from  2006  I  am  eager  to  find  a  similar,  more  current breakdown.},
  doi       = {https://doi.org/10.1007/s11119-006-9014-9},
  file      = {:/home/sd/Documents/papers/Pedersen2006_Article_AgriculturalRobotsSystemAnalys.pdf:PDF},
  keywords  = {rank3},
  publisher = {Springer Science and Business Media {LLC}},
  ranking   = {rank3},
}

@Article{Weiss2011,
  author    = {Ulrich Weiss and Peter Biber},
  journal   = {Robotics and Autonomous Systems},
  title     = {Plant detection and mapping for agricultural robots using a 3D {LIDAR} sensor},
  year      = {2011},
  month     = {may},
  number    = {5},
  pages     = {265--273},
  volume    = {59},
  comment   = {A key problem in agricultural robots is to detect and map individual plants for several reasons, including 
navigation, individual reports and individual care. For a robust plant mapping it is needed to use reliable
sensors and algorithms. Much research is done in solving this problem 
using 2D and 3D cameras but this paper on the other hand, works on detecting plants using low cost and low resolution
3D Lidar sensors. The solution contains an algorithm for detecting individual plant in a row using a FX6 3D Lidar sensor. 
This sensor is still in development, the current version has a resolution of 29 by 59 pixel creating 15 frames per second.
To detect the plant from the resulting point cloud, the algorithm first detects the ground plane and second  
creates cluster for each plants using a k,d tree and decides for each cluster only using the bounding box dimensions.
The proposed algorithm works seemingly fast, and manages to identify in a single frame 60\% of the plants
and using multiple frames with tracking it scores an average detection accuracy of 80-90\%. Further the average accuracy 
of the position detection is 3 centimeters. One problem occurring repeatedly is that the algorithm fails to differentiate
between the next plants if they grow into each other and the cluster connect. The idea to use a low cost 3D sensor is quite good because, as mentioned in the paper, it works independent from 
existing lighting and is robust against fog and dust - conditions which occur frequently in the real world.
The algorithm uses only a bounding box of a cluster to determine the position of the plant. This approach works okay 
when every plant grows neatly far away from their neighbours but fails in messy real world conditions.
Some aspects are great on the other hand, it has a fast runtime, for example. I think this given approach would work 
better on a row basis and maybe use offline compute power to identify the individual plants? 
Because measuring these plants is a repeated operation, one could leverage the result of a computational more expensive
offline algorithm and map the online point cloud directly onto an existing map.
This main contribution is an evaluation of a low-cost 3D lidar scanner with an basic point clustering algorithm in real time. besides
that they also showcase other approaches for the same problem using traditional 2D camera systems and different scanners.
The future research will include using stronger machine learning algorithms for clustering and plant separation. They also
want to work on a row detection basis.
My main concern was the quite simple simulation model on gazebo and i hope that they improve this.
It is possible to detect plants in real time using point clouds in the agricultural sector even with 
simple mathematical methods. The difference between a classical and those FX6 laser scanner is also interesting.
I think plant detection like this is the way to go, by improving only the algorithm it should be possible
soon to deploy at least field scouting robots in real world scenarios. 
In depth paper for clustering point clouds into individual plants using a bounding box approach.
Maths is explained nicely, can be used to build something similar.},
  doi       = {https://doi.org/10.1016/j.robot.2011.02.011},
  file      = {:/home/sd/Documents/papers/1-s2.0-S0921889011000315-main.pdf:PDF},
  keywords  = {rank4},
  publisher = {Elsevier {BV}},
  ranking   = {rank4},
}

@Article{Vasconez2019,
  author    = {Juan P. Vasconez and George A. Kantor and Fernando A. Auat Cheein},
  journal   = {Biosystems Engineering},
  title     = {Human{\textendash}robot interaction in agriculture: A survey and current challenges},
  year      = {2019},
  month     = {mar},
  pages     = {35--48},
  volume    = {179},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2018.12.005},
  file      = {:/home/sd/Documents/papers/vasconez2019.pdf:PDF},
  priority  = {31},
  publisher = {Elsevier {BV}},
}

@Article{Jones2019,
  author    = {Mark H. Jones and Jamie Bell and Daniel Dredge and Matthew Seabright and Alistair Scarfe and Mike Duke and Bruce MacDonald},
  journal   = {Biosystems Engineering},
  title     = {Design and testing of a heavy-duty platform for autonomous navigation in kiwifruit orchards},
  year      = {2019},
  month     = {nov},
  pages     = {129--146},
  volume    = {187},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2019.08.019},
  file      = {:/home/sd/Documents/papers/jones2019.pdf:PDF},
  priority  = {5},
  publisher = {Elsevier {BV}},
}

@Misc{Griswold2009,
  author = {Griswold, William},
  title  = {How to read an engineering research paper},
  year   = {2009},
  file   = {:/home/sd/Documents/papers/How_to_Read_an_Engineering_Research_Paper.pdf:PDF},
  url    = {http://weibel.ucsd.edu/download/cse118/How_to_Read_an_Engineering_Research_Paper.pdf},
}

@Misc{Huang2000,
  author = {Huang, Wes},
  title  = {How to read a research paper},
  year   = {2000},
  file   = {:/home/sd/Documents/papers/howtoread.pdf:PDF},
  url    = {https://www.cs.cmu.edu/~motionplanning/reading/howtoread.pdf},
}

@Article{Choi2020,
  author    = {Sang Hyun Choi and Vikyath D. Rao and Tim Gernat and Adam R. Hamilton and Gene E. Robinson and Nigel Goldenfeld},
  journal   = {Proceedings of the National Academy of Sciences},
  title     = {Individual variations lead to universal and cross-species patterns of social behavior},
  year      = {2020},
  month     = {nov},
  pages     = {202002013},
  doi       = {https://doi.org/10.1073/pnas.2002013117},
  publisher = {Proceedings of the National Academy of Sciences},
  url       = {https://www.igb.illinois.edu/article/unexpected-similarity-between-honey-bee-and-human-social-life},
}
{Siciliano2016,
  author    = {Bruno Siciliano and Oussama Khatib},
  editor    = {Bruno Siciliano and Oussama Khatib},
  publisher = {Springer International Publishing},
  title     = {Springer Handbook of Robotics},
  year      = {2016},
  abstract  = {Robotics for agriculture and forestry (A&F) rep-
resents the ultimate application of one of our
society’s latest and most advanced innovations
to its most ancient and important industries.
Over the course of history, mechanization and au-
tomation increased crop output several orders of
magnitude, enabling a geometric growth in pop-
ulation and an increase in quality of life across
the globe. Rapid population growth and rising
incomes in developing countries, however, re-
quire ever larger amounts of A&F output. This
chapter addresses robotics for A&F in the form
of case studies where robotics is being success-
fully applied to solve well-identified problems.
With respect to plant crops, the focus is on the
in-field or in-farm tasks necessary to guarantee
a quality crop and, generally speaking, end at
harvest time. In the livestock domain, the focus
is on breeding and nurturing, exploiting, harvest-
ing, and slaughtering and processing. The chapter
is organized in four main sections. The first one
explains the scope, in particular, what aspects
of robotics for A&F are dealt with in the chap-
ter. The second one discusses the challenges and
opportunities associated with the application of
robotics to A&F. The third section is the core of
the chapter, presenting twenty case studies that
showcase (mostly) mature applications of robotics
in various agricultural and forestry domains. The
case studies are not meant to be comprehen-
sive but instead to give the reader a general
overview of how robotics has been applied to
A&F in the last 10 years. The fourth section con-
cludes the chapter with a discussion on specific
improvements to current technology and paths to
commercialization.},
  comment   = {Questions
What are the motivations for this work?
Optimized Coverage for Arable Farming
• Minimizes soil compaction
• Reduces fuel cost
• Reduces time needed
Weed Control
• Weeds directly reduce yield by competing the crops over light, water
and nutrients
• Weed control is needed to stop them from spreading
• Robotic control system offer greater mechanical precision and a re-
duction in herbicides needed.
High Precision Seeding
• When knowing the exact location of the seeded crops all following
robotic operation can use this data
• No further local sensing is needed
• Can also be used as an input for localization
Crop Yield Estimation
• manually gathering the required data is labour- and time-consuming
error prone process.
• accurate estimations will help growers in labour demand forecasting.
• Better planning reduces costs by optimizing packing and storage ca-
pacity.
Precision Irrigation Conventional irrigation technologies dent to over-watering.
This is of course wasteful and also increases leaching of fertilizers.
Tree Fruit Production
• One of the hardest problems of farming because of the complex tree
geometry
• Sloped terrain (vineyards)
• Need to sense the branches
• Occlusion of the fruits
Vehicle Formation control Using multiple robots together will increase the
capabilities even further. One element of MRS is to control robots in a
formation.
Plant Probing
• Automated sample taking will enable large scale experiments.
• It is hard to model deformable objects like plant parts (leaves, stems,
flowers, fruits)
• Proper models will enable individual plant part care, sampling, har-
vesting, predicting, robotized phenotyping
Cucumber Harvesting Automated harvesting can improve efficiency and re-
duce labour costs. The same system can also be used to cut nonproductive
leaves from the plants.
What is the proposed solution?
Optimized Coverage for Arable Farming
• Find the optimal way to move around in complex terrain.
• Introduction of Optimal coverage planning algorithm
Weed Control
• A robotic system to drive autonomous over trough the fields.
• machine vision based approach to identify weeds
• precise distribution of herbicides
High Precision Seeding
• a driver-less seeding system with high accuracy localization
• smaller wheels allow driving between ros eliminating soil compaction
Crop Yield Estimation
• A machine vision based system which is able to identify crops
• the system is manually driven through orchards at night and takes
pictures with artificial light
• works for vineyards, apple orchards and strawberry ranches.
Precision Irrigation A wireless sensor network monitoring the exact soil con-
ditions.
Tree Fruit Production
• Proposed a family of autonomous orchard vehicles.
• Only uses laser range finders, no gps for keeping the cost low
• Designed in a way to enable faster working human labourers.
Vehicle Formation control
• a control architecture based on a path tracking framework.
• should allow multiple robots to continue to drive in formation even
in ruff terrain with poor grip conditions.
• the system uses RTK-GPS with an accuracy of 2cm.
• wireless communications between robots to communicate relative po-
sitions
Plant Probing
• System consisting of a robotic arm, time-of-flight camera and a mea-
surement technologies
• image segmentation and model fitting are used to find single leaves
from depth informations
• The robot arms first finds position from where it can see the whole
plant and then it moves further to enable unobstructed viewing of a
single leave.
• After selecting a target leave it will take a probe.
Cucumber Harvesting
• Mobile platform mounted on rails in greenhouses
• Harvesting contains several subproblems, one of them is finding the
ripeness of the crops. In this case a target weight is given. Because
cucumbers are mostly water it is possible to determine the weight
from 3D data.
• The system has a single camera but it is possible to move it around
to capture the needed 3D informations.
• After identifying the ripe cucumber, it is cut and moved collision free
to a storage crate.
What is the work‘s evaluation of the solution?
Optimized Coverage for Arable Farming
• reduces turns needed ca. 15%
• reduces soil erosion cost ca. 25%
• reduces skipped area cost ca. 81%
Weed Control
• 77% of weeds got precisely eradicated
• reduction in herbicides
High Precision Seeding Not much data given, needs further study.
Crop Yield Estimation The results show that the system works surprisingly
well in a different environments.
Precision Irrigation
• reduces the water needed by 75% against conventional watering
• should allow multiple robots to continue to drive in formation even
in ruff terrain with poor grip conditions.
Tree Fruit Production The different approaches followed by the original au-
thors showed that they are twice as fast as manual labor.
Vehicle Formation control
• they tested using two robots, where one should follow the other in a
defined distance along sloped terrain
• the two robots managed to stay in their path with an accuracy of
15cm
Plant Probing In the summary is no further evaluation. Needs additional
study!
Cucumber Harvesting
• The system needs on average 65 seconds to cut one cucumber
• Success rate: ca. 75%
What are the contributions?
Optimized Coverage for Arable Farming Finds Optimal paths for 2D and
3D terrain with soil erosion models.
Weed Control They presented 3 different systems to autonomously kill weeds
in different scenarios. The second one (volunteer potatoes in sugar beets)
seemed like the best one. Further research here!
High Precision Seeding Complete system which achieves high precision seed-
ing.
Crop Yield Estimation A camera rig for small tractors to gather data, can
be further improved in the future.
Precision Irrigation Wireless system for monitoring and control
Tree Fruit Production 3 different autonomous platforms navigating by them
selves inside orchards. The system has accumulated 350km driven.
Vehicle Formation control A control architecture for two or more robots to
stay in formation.
Plant Probing Stationary system to take leave samples.
Cucumber Harvesting Whole system harvesting cucumbers and cutting leaves.
Has algorithm to determine the ripeness and for finding paths for collision
free manipulations.
What questions have I left?
Optimized Coverage for Arable Farming What is about the path length
and exact fuel reduction?
Weed Control How is it possible to increase the velocity further? The ma-
chines are too slow.
High Precision Seeding Concrete implementations for further data fusion of
seed map with the next scans for a living yield map.
Crop Yield Estimation Why is the system not self driving?
Precision Irrigation The savings in water needed and increase in growth
speed are really impressive. How did this work? Did they somehow cheat
on the data? Definitely study the original paper.
Tree Fruit Production Of course using vehicles is faster than manual work
using ladders - but are they faster using the same approach with drivers?
How does the navigation work with no GPS?
Vehicle Formation control How valid are the results today? Driving two
robots in grass does not sound to impressive.
Plant Probing Can this system be mounted on rails?
Cucumber Harvesting How does the accuracy shrink when speeding the pro-
cess up? How fast can this scale up?
Summary
Summarizes many different papers in-depth. Refer to this for further research.
Rating
5/5
\},
  doi       = {https://doi.org/10.1007/978-3-319-32552-1},
  file      = {:/home/sd/Documents/books/2016_Book_SpringerHandbookOfRobotics.pdf:PDF},
  keywords  = {Overview, Case studies, weed control, high precision farming, crop yield estimation, Vehicle formation control, plant probing, leaf removal, harvesting, precision forestry, aerial based precision farming, rank5},
  ranking   = {rank5},
}

@InProceedings{Dong2014,
  author    = {Jing Dong and Luca Carlone and Rains, {Glen C.} and Tim Coolong and Frank Dellaert},
  booktitle = {American Society of Agricultural and Biological Engineers Annual International Meeting 2014, ASABE 2014},
  title     = {4D mapping of fields using autonomous ground and aerial vehicles},
  year      = {2014},
  address   = {United States},
  note      = {American Society of Agricultural and Biological Engineers Annual International Meeting 2014, ASABE 2014 ; Conference date: 13-07-2014 Through 16-07-2014},
  pages     = {4270--4276},
  publisher = {American Society of Agricultural and Biological Engineers},
  series    = {American Society of Agricultural and Biological Engineers Annual International Meeting 2014, ASABE 2014},
  abstract  = {In this study, we propose a novel technique for imaging of crops. Related work has significant limitations in terms of resolution as well as coverage in space and time. In order to overcome these limitations, we use a dense sampling of high-resolution images, which enables the creation of a sequence of 3D reconstructions over time, i.e., a 4D spatio-temporal model of a crop as it develops. To this end, we mounted a CCD camera with integrated GPS and Inertial Measurement Unit (IMU) on a ground articulated tractor, and we collected a set of images approximately once per week over staggered plantings of broccoli from October to January in South Georgia. Multiple images of individual plants taken from different angles are stitched together to produce a 3D reconstruction each week, using {"}Structure from Motion{"} (SFM) techniques from computer vision. These 3D reconstructions are then combined in a 4D GIS to show the plants growth and production of fruit over time (4D). These 4D imaging techniques can be applied to images collected from autonomous ground or aerial vehicles for multiple site-specific management practices, such as estimating where, when and how many fruit are ready for harvest in certain vegetable and fruit crops. Other potential applications include record keeping of canopy development for orchards, measuring rate of change of leaf area index, and weed dispersal, proliferation and identification.},
  doi       = {10.13031/aim.20141912258},
  file      = {:/home/sd/Documents/papers/4d-mapping-of-fields-using-autonomous-ground-and-aerial-vehicles-2014.pdf:PDF},
  language  = {English},
  priority  = {7},
}

@Article{Henten2003,
  author    = {E.J. Van Henten and B.A.J. Van Tuijl and J. Hemming and J.G. Kornet and J. Bontsema and E.A. Van Os},
  journal   = {Biosystems Engineering},
  title     = {Field Test of an Autonomous Cucumber Picking Robot},
  year      = {2003},
  month     = {nov},
  number    = {3},
  pages     = {305--313},
  volume    = {86},
  abstract  = {At the Institute of Agricultural and Environmental Engineering (IMAG B.V.) an autonomous harvesting
robot for cucumbers was developed and tested in a greenhouse in autumn 2001. Analysis of the harvest
process had revealed that at a 2 ha Dutch production facility four robots are needed to replace the skilled
human work force during the peak season. Then assuming a success rate of 100%, a harvest cycle might take
at most 10 s per cucumber fruit. In this paper the results of the field test of the harvesting robot are reported
and analysed in view of the performance criteria mentioned above. Cucumbers (Cucumis sativus cv. Korinda)
were grown in a high-wire cultivation system. In four independent experiments the robot was tested. The
average success rate was 744%. The majority of failures originated from inaccurate positioning of the end-
effector at the stalk of the fruit. It was found to be a great advantage that the system was able to perform
several harvest attempts on a single cucumber from different harvest positions of the robot. This improved the
success rate considerably. A single successful harvest cycle took 652 s per cucumber. Since not all attempts
were successful, a cycle time of 124 s per harvested cucumber was measured under practical circumstances. The
test confirmed the ability to harvest more than one cucumber using a single set of images which reduced the
cycle time of a successful harvest to 567 and 530 s if two or three cucumbers were harvested. To bridge the
gap between the measured performance and the design specifications, future research focuses on improving the
success rate, faster hardware and software for image processing and motion planning as well as the reduction
of the motion time of the manipulator.},
  comment   = {What are the motivations for this work?
• The authors wanted to create a comparable solution to recent advances in
harvesting tomatoes and eggplants
• Human labour fir harvesting is a tedious and expensive task.
• Robot labour needs to be able to harvest one cucumber every 10 seconds.
This experiment tries to show the current (2001) limitations.
• Inside high-wire greenhouses mobile robots can move along tracks next to
the cucumber plants which creates a somehow structured environment.
• This proposed architecture should allow complete autonomous harvesting.
What is the proposed solution?
• Mobile system consisting of a robotic arm having a thermal cutter and a
suction cup for cutting and grabbing the cucumbers. One camera for tak-
ing two images (768x512px) at different positions to find 3D coordinates.
• They restricted the way to cucumbers could grow so that they are always
in a specific range reachable for the robots manipulators.
• Removed leaves before hand to lessen occlusion errors.
• They also removed cucumbers growing too close to each other.
• The systems moves along a rail in 33cm steps. At each step the cam-
eras look for cucumbers and if found and big enough proceed with the
harvesting.
• The harvesting does not take additional images. All informations come
from the initial 2 pictures. Even if multiple cucumbers are found, the
initial information and processing has to be enough.
• Because the range of the system is around 1m, the 33cm step allow up to
3 harvest attempts for each cucumber.
What is the work‘s evaluation of the solution?
• For this experiment the authors took in-depth runtime measurements and
error protocols.
• On average the system managed to harvest ca. 75% of a present cucum-
bers.
• For the whole experiment with multiple attempts and failures, the result-
ing harvesting time was 124s per cucumber!!!
• If every first attempt would have been successful, the resulting time would
have been 75s per harvested cucumber.
• Most errors (ca. 36%) came from an misplaced end-effector resulting from
poor 3D coordinates.
What is my analysis of the identified problem, idea and evaluation?
• Those experiments (20 years ago) have been one order of magnitude too
slow for a commercial application.
• I like the idea of using only one camera, but the extra cost would directly
result in a speed up which would basically pay for itself to use a stereo
camera.
• The evaluation was very good. The authors managed to create an details
overview over the shortcomings.
• Especially the failure categorization is great. This should be an inspiration
for similar failure reports for my own experiments.
• I was surprised that the paper was that old.
• 10 seconds runtime for the image analysis will be much faster nowadays.
What are the contributions?
• This paper was a report over an in depth experiment using this harvesting
system.
• It sheds light in many failure classes and shows how to make a proper
report.
• The robotic system had a bad execution time and accuracy.
What are the future directions of the research?
Harvesting crops in greenhouses will continue to be a key research topic. For
this case I hope that the authors managed to increase the execution speeds.
What questions have I left?
• Mainly the comparison to todays systems. For the my next reading report
I should find a more recent paper about the same topic.
• If the system can easily exchange the end-effectors, it should be possible
to use the mobile platform for all kind of different tasks.
What is my main take away from this paper?
Great structured experiment with a promising setup. Having rails in a green-
house is not too expensive and solves many navigation problems. I am looking
forward to deepen my research in this area. Would it be possible to create a
rail grid with multiple robots, cooperating in this task?
Summary
Definitely enjoyed the detailed reporting on different failures and execution
times. This paper is an excellent blueprint on how to write a report over an
experiment.
Rating
4/5},
  doi       = {https://doi.org/10.1016/j.biosystemseng.2003.08.002},
  file      = {:/home/sd/Documents/papers/vanhenten2003.pdf:PDF},
  keywords  = {Harvesting, Computer Vision, Machine Vision, Stereo Vision, Experiment, rank3},
  publisher = {Elsevier {BV}},
  ranking   = {rank3},
}

@Article{Alenya2014,
  author    = {G. Aleny{\`{a}} and S. Foix and C. Torras},
  journal   = {Intelligent Service Robotics},
  title     = {Using {ToF} and {RGBD} cameras for 3D robot perception and manipulation in human environments},
  year      = {2014},
  month     = {sep},
  number    = {4},
  pages     = {211--220},
  volume    = {7},
  doi       = {https://doi.org/10.1007/s11370-014-0159-5},
  file      = {:/home/sd/Documents/papers/Alenyà2014_Article_UsingToFAndRGBDCamerasFor3DRob.pdf:PDF},
  priority  = {12},
  publisher = {Springer Science and Business Media {LLC}},
}

@InBook{Wang2013,
  author    = {Wang, Qi and Nuske, Stephen and Bergerman, Marcel and Singh, Sanjiv},
  editor    = {Desai, Jaydev P. and Dudek, Gregory and Khatib, Oussama and Kumar, Vijay},
  pages     = {745--758},
  publisher = {Springer International Publishing},
  title     = {Automated Crop Yield Estimation for Apple Orchards},
  year      = {2013},
  address   = {Heidelberg},
  isbn      = {978-3-319-00065-7},
  abstract  = {Crop yield estimation is an important task in apple orchard management. The current manual sampling-based yield estimation is time-consuming, labor-intensive and inaccurate. To deal with this challenge, we developed a computer vision-based system for automated, rapid and accurate yield estimation. The system uses a two-camera stereo rig for image acquisition. It works at nighttime with controlled artificial lighting to reduce the variance of natural illumination. An autonomous orchard vehicle is used as the support platform for automated data collection. The system scans both sides of each tree row in orchards. A computer vision algorithm detects and registers apples from acquired sequential images, and then generates apple counts as crop yield estimation. We deployed the yield estimation system in Washington state in September, 2011. The results show that the system works well with both red and green apples in the tall-spindle planting system. The crop yield estimation errors are -3.2{\%} for a red apple block with about 480 trees, and 1.2{\%} for a green apple block with about 670 trees.},
  booktitle = {Experimental Robotics: The 13th International Symposium on Experimental Robotics},
  doi       = {10.1007/978-3-319-00065-7_50},
  file      = {:/home/sd/Documents/papers/wang2013.pdf:PDF},
  priority  = {48},
  url       = {https://doi.org/10.1007/978-3-319-00065-7_50},
}

@Article{Katupitiya2007,
  author    = {Jayantha Katupitiya and Ray Eaton and Tahir Yaqub},
  title     = {Systems Engineering Approach to Agricultural Automation: New Developments},
  year      = {2007},
  month     = {apr},
  booktitle = {2007 1st Annual {IEEE} Systems Conference},
  doi       = {https://doi.org/10.1109/SYSTEMS.2007.374688},
  file      = {:/home/sd/Documents/papers/katupitiya2007.pdf:PDF},
  priority  = {20},
  publisher = {{IEEE}},
}

@Article{Mao2020,
  author    = {Shihan Mao and Yuhua Li and You Ma and Baohua Zhang and Jun Zhou and Kai Wang},
  journal   = {Computers and Electronics in Agriculture},
  title     = {Automatic cucumber recognition algorithm for harvesting robots in the natural environment using deep learning and multi-feature fusion},
  year      = {2020},
  month     = {mar},
  pages     = {105254},
  volume    = {170},
  doi       = {https://doi.org/10.1016/j.compag.2020.105254},
  file      = {:/home/sd/Documents/papers/mao2020.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Kurtser2020,
  author    = {Polina Kurtser and Yael Edan},
  journal   = {Robotics and Autonomous Systems},
  title     = {Planning the sequence of tasks for harvesting robots},
  year      = {2020},
  month     = {sep},
  pages     = {103591},
  volume    = {131},
  doi       = {https://doi.org/10.1016/j.robot.2020.103591},
  file      = {:/home/sd/Documents/papers/10.1016@j.robot.2020.103591.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Davidson2020,
  author    = {Joseph Davidson and Santosh Bhusal and Changki Mo and Manoj Karkee and Qin Zhang},
  journal   = {Global Journal of Agricultural and Allied Sciences},
  title     = {Robotic Manipulation for Specialty Crop Harvesting: A Review of Manipulator and End-Effector Technologies},
  year      = {2020},
  month     = {sep},
  number    = {1},
  pages     = {25--41},
  volume    = {2},
  doi       = {https://doi.org/10.35251/gjaas.2020.004},
  file      = {:/home/sd/Documents/papers/17-Article Text-57-1-10-20200909.pdf:PDF},
  publisher = {Association of Nepalese Agricultural Professionals of Americas},
}

@Article{Kayacan2018,
  author    = {Erkan Kayacan and Sierra N. Young and Joshua M. Peschel and Girish Chowdhary},
  journal   = {Journal of Field Robotics},
  title     = {High-precision control of tracked field robots in the presence of unknown traction coefficients},
  year      = {2018},
  month     = {jun},
  number    = {7},
  pages     = {1050--1062},
  volume    = {35},
  doi       = {https://doi.org/10.1002/rob.21794},
  file      = {:/home/sd/Documents/papers/kayacan2018.pdf:PDF},
  publisher = {Wiley},
}

@Article{Lili2017,
  author    = {Wang Lili and Zhao Bo and Fan Jinwei and Hu Xiaoan},
  journal   = {International Journal of Agricultural and Biological Engineering},
  title     = {Development of a tomato harvesting robot used in greenhouse},
  year      = {2017},
  number    = {4},
  pages     = {140--149},
  volume    = {10},
  abstract  = {A tomato harvesting robot was developed in this study, which consisted of a four-wheel independent steering system,
a 5-DOF harvesting system, a navigation system, and a binocular stereo vision system.
 The four-wheel independent steering
system was capable of providing a low-speed steering control of the robot based on Ackerman steering geometry.
 The
proportional-integral-derivative (PID) algorithm was used in the laser navigation control system. The Otsu algorithm and the
elliptic template method were used for the automatic recognition of ripe tomatoes, and obstacle avoidance strategies were
proposed based on the C-space method.
 The maximum average absolute error between the set angle and the actual angle was
about 0.14°, and the maximum standard deviation was about 0.04°.
 The laser navigation system was able to rapidly and
accurately track the path, with the deviation being less than 8 cm.
 The load bearing capacity of the mechanical arm was about
1.5 kg.
 The success rate of the binocular vision system in the recognition of ripe tomatoes was 99.3%.
 When the distance
was less than 600 mm, the positioning error was less than 10 mm.
 The time needed for recognition of ripe tomatoes and
pitching was about 15 s per tomato, with a success rate of about 86%. This study provides some insights into the development
and application of tomato harvesting robot used in the greenhouse.},
  comment   = {What are the motivations for this work?
• Harvesting tomatoes is a very popular and labour intensive vegetable. The
annual production is around 60 million tons.
• Because the labor costs are rising - even in China they are trying to find
a autonomous solution which can scale up.
• Tomatoes are very soft and sensitive vegetables so harvesting them is
especially complicated.
• The authors name several other research in building this kind of harvesting
robots, but those have slow reaction and clumsy movement.
• They want to create a fast system for picking tomatoes in greenhouses
What is the proposed solution?
• A robot system capable of :
– Automatic navigation
– Recognition of ripeness
– Detecting the exact position of the ripe fruits
– Avoiding obstacles.
• The solution also contains a image recognition algorithm and a picking
control method.
• The shown robot has a four-wheel drive with independent steering. The
4 wheels are controlled using and Ackermann steering model.
• It detects tomatoes using a stereo-vision camera with a resolution of
1384×1032px
• The pathfinding is done by using a laser scanner
• To pick the ripe tomatoes, the robot has a 4-DOF mechanical arm with a
1-DOF end-effector
• After picking the tomatoes the robot outs them into a crate on its back.
• The total mass of the robot is 540 kg and it reaches an maximum speed
of 3.6 km/h.
What is the work‘s evaluation of the solution?
• The authors evaluated every part of their system:
– The controlling of the steering angle resulted in an average error
of 0.14° with a standard deviation of 0.04°.
– Path tracking by the navigation system could track the correct
path with a deviation of less than 8cm.
– They also evaluated how much weight the mechanical arm the end-
effector can carry without loosing precision. When using weights up
to 1kg no big deviation is measured. So the mechanical system is fit
for its main goal of manipulating tomatoes.
– Inside the greenhouse the camera-system has to detect the toma-
toes. Here the authors measured a success rate of over 99.3% in a
sample size of 300.
– The position of the tomatoes got detected correctly with an average
positioning error of less than 10mm in a range of 600mm.
– Finally the picking rate of the robot was measured to be 87% in
a sample size of 100 tomatoes. The robot needs 15 seconds from
recognition to pitching the tomatoes.
What is my analysis of the identified problem, idea and evaluation?
• This paper contains multiple system working together for a common goal.
It showcases the steps needed to make the robot drive through a green-
house and pick tomatoes.
• The error and performance analyses is detailed. Only thing lacking is an
in-depth breakdown of the task times. The only time measurement in the
paper is the 15 seconds from recognition to picking - but how long does
the robot need to pick 100 tomatoes?
• Tomato picking has the advantage that tomatoes are easy to detect via
camera. A disadvantage is the soft nature of the fruits.
What are the contributions?
• Algorithm to track the path inside a greenhouse using laser scanner
• Control architecture for the mechanical arm using a collision free A*-
algorithm.
• Tomato detection and localisation algorithms using stereo vision
• In-depth error analysis.
What are the future directions of the research?
• Improving the success rate and overall speed.
• Using this system to other crops.
What questions have I left?
• They left out some key metrics like time breakdown and total time needed.
So I would like to know if this system is even fast enough for a commercial
consideration
• I have not fully understand how the collision free path finding algorithm
for the end-effector works, so this is something to study next.
• Currently the robot is only following along the space in between two rows
in a greenhouse. It would be great to add additional navigation systems
for a a fully automated operation.
What is my main take away from this paper?
• The localisation in a greenhouse for tomatoes works good enough to grap
them. I did not expect for this to work that good.
• This paper is a good study of a holistic robot system working in the chaotic
environment of a greenhouse.
Summary
This paper is a good study of a holistic robot system working in the chaotic
environment of a greenhouse. But some key performance indicator are missing,
even some already mentioned in the introduction. In the motivation section of
the paper they said that other systems would be too slow but did not deliver
they own number. Nevertheless a good study and nice read.
Rating
3/5},
  doi       = {10.25165/j.ijabe.20171004.3204},
  file      = {:/home/sd/Documents/papers/Lili2017.pdf:PDF},
  keywords  = {tomato harvesting robot, four-wheel independent steering, automatic navigation, binocular stereo vision system, obstacle avoidance, greenhouse, rank3},
  publisher = {International Journal of Agricultural and Biological Engineering},
  ranking   = {rank3},
}

@Article{Arad2020,
  author    = {Boaz Arad and Jos Balendonck and Ruud Barth and Ohad Ben-Shahar and Yael Edan and Thomas Hellström and Jochen Hemming and Polina Kurtser and Ola Ringdahl and Toon Tielen and Bart Tuijl},
  journal   = {Journal of Field Robotics},
  title     = {Development of a sweet pepper harvesting robot},
  year      = {2020},
  month     = {jan},
  number    = {6},
  pages     = {1027--1039},
  volume    = {37},
  doi       = {https://doi.org/10.1002/rob.21937},
  file      = {:/home/sd/Documents/papers/10.1002@rob.21937.pdf:PDF},
  keywords  = {rank5},
  publisher = {Wiley},
  ranking   = {rank5},
}

@Book{Siciliano2016,
  author    = {Siciliano, Bruno and Khatib, Oussama},
  publisher = {Springer},
  title     = {Springer handbook of robotics},
  year      = {2016},
  file      = {:/home/sd/Documents/books/2016_Book_SpringerHandbookOfRobotics.pdf:PDF},
  url       = {https://link.springer.com/book/10.1007/978-3-319-32552-1},
}

@Article{Li2017,
  author    = {Dawei Li and Lihong Xu and Xue-song Tang and Shaoyuan Sun and Xin Cai and Peng Zhang},
  journal   = {Remote Sensing},
  title     = {3D Imaging of Greenhouse Plants with an Inexpensive Binocular Stereo Vision System},
  year      = {2017},
  month     = {may},
  number    = {5},
  pages     = {508},
  volume    = {9},
  doi       = {https://doi.org/10.3390/rs9050508},
  file      = {:/home/sd/Documents/papers/li2017.pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@Article{2016,
  title     = {Comparison of Structure-from-Motion and Stereo Vision Techniques for Full In-Field 3D Reconstruction and Phenotyping of Plants: An Investigation in Sunflower},
  year      = {2016},
  month     = {jul},
  booktitle = {2016 {ASABE} International Meeting},
  doi       = {10.13031/aim.20162444593},
  file      = {:/home/sd/Documents/papers/comparison-of-structurefrommotion-and-stereo-vision-techniques-f-2016.pdf:PDF},
  publisher = {American Society of Agricultural and Biological Engineers},
}

@Article{ZapoteznyAnderson2019,
  author    = {Paul Zapotezny-Anderson and Chris Lehnert},
  journal   = {{IFAC}-{PapersOnLine}},
  title     = {Towards Active Robotic Vision in Agriculture: A Deep Learning Approach to Visual Servoing in Occluded and Unstructured Protected Cropping Environments},
  year      = {2019},
  number    = {30},
  pages     = {120--125},
  volume    = {52},
  doi       = {https://doi.org/10.1016/j.ifacol.2019.12.508},
  file      = {:/home/sd/Documents/papers/zapotezny-anderson2019.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Zhang2020,
  author    = {Baohua Zhang and Yuanxin Xie and Jun Zhou and Kai Wang and Zhen Zhang},
  journal   = {Computers and Electronics in Agriculture},
  title     = {State-of-the-art robotic grippers, grasping and control strategies, as well as their applications in agricultural robots: A review},
  year      = {2020},
  month     = {oct},
  pages     = {105694},
  volume    = {177},
  doi       = {https://doi.org/10.1016/j.compag.2020.105694},
  file      = {:/home/sd/Documents/papers/10.1016@j.compag.2020.105694.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Wu2020,
  author     = {Gang Wu and Bin Li and Qibing Zhu and Min Huang and Ya Guo},
  journal    = {Computers and Electronics in Agriculture},
  title      = {Using color and 3D geometry features to segment fruit point cloud and improve fruit recognition accuracy},
  year       = {2020},
  month      = {jul},
  pages      = {105475},
  volume     = {174},
  doi        = {https://doi.org/10.1016/j.compag.2020.105475},
  file       = {:/home/sd/Documents/papers/10.1016@j.compag.2020.105475.pdf:PDF},
  keywords   = {read, rank4},
  publisher  = {Elsevier {BV}},
  ranking    = {rank4},
  readstatus = {read},
}

@Article{Tao2017,
  author    = {Yongting Tao and Jun Zhou},
  journal   = {Computers and Electronics in Agriculture},
  title     = {Automatic apple recognition based on the fusion of color and 3D feature for robotic fruit picking},
  year      = {2017},
  month     = {nov},
  pages     = {388--396},
  volume    = {142},
  doi       = {https://doi.org/10.1016/j.compag.2017.09.019},
  file      = {:/home/sd/Documents/papers/tao2017.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Guerrero2017,
  author    = {Jos{\'{e}} Miguel Guerrero and Jos{\'{e}} Jaime Ruz and Gonzalo Pajares},
  journal   = {Computers and Electronics in Agriculture},
  title     = {Crop rows and weeds detection in maize fields applying a computer vision system based on geometry},
  year      = {2017},
  month     = {nov},
  pages     = {461--472},
  volume    = {142},
  doi       = {https://doi.org/10.1016/j.compag.2017.09.028},
  file      = {:/home/sd/Documents/papers/guerrero2017.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Li2020,
  author    = {Zhenbo Li and Ruohao Guo and Meng Li and Yaru Chen and Guangyao Li},
  journal   = {Computers and Electronics in Agriculture},
  title     = {A review of computer vision technologies for plant phenotyping},
  year      = {2020},
  month     = {sep},
  pages     = {105672},
  volume    = {176},
  doi       = {https://doi.org/10.1016/j.compag.2020.105672},
  file      = {:/home/sd/Documents/papers/10.1016@j.compag.2020.105672.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{GeneMola2020,
  author    = {Jordi Gen{\'{e}}-Mola and Ricardo Sanz-Cortiella and Joan R. Rosell-Polo and Josep-Ramon Morros and Javier Ruiz-Hidalgo and Ver{\'{o}}nica Vilaplana and Eduard Gregorio},
  journal   = {Computers and Electronics in Agriculture},
  title     = {Fruit detection and 3D location using instance segmentation neural networks and structure-from-motion photogrammetry},
  year      = {2020},
  month     = {feb},
  pages     = {105165},
  volume    = {169},
  doi       = {https://doi.org/10.1016/j.compag.2019.105165},
  file      = {:/home/sd/Documents/papers/10.1016@j.compag.2019.105165.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Zermas2020,
  author    = {Dimitris Zermas and Vassilios Morellas and David Mulla and Nikos Papanikolopoulos},
  journal   = {Computers and Electronics in Agriculture},
  title     = {3D model processing for high throughput phenotype extraction {\textendash} the case of corn},
  year      = {2020},
  month     = {may},
  pages     = {105047},
  volume    = {172},
  doi       = {https://doi.org/10.1016/j.compag.2019.105047},
  file      = {:/home/sd/Documents/papers/10.1016@j.compag.2019.105047.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Ge2019,
  author    = {Yuanyue Ge and Ya Xiong},
  journal   = {{IFAC}-{PapersOnLine}},
  title     = {Instance Segmentation and Localization of Strawberries in Farm Conditions for Automatic Fruit Harvesting},
  year      = {2019},
  number    = {30},
  pages     = {294--299},
  volume    = {52},
  doi       = {https://doi.org/10.1016/j.ifacol.2019.12.537},
  file      = {:/home/sd/Documents/papers/ge2019.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Hameed2018a,
  author    = {Khurram Hameed and Douglas Chai and Alexander Rassau},
  journal   = {Image and Vision Computing},
  title     = {A comprehensive review of fruit and vegetable classification~techniques},
  year      = {2018},
  month     = {dec},
  pages     = {24--44},
  volume    = {80},
  doi       = {https://doi.org/10.1016/j.imavis.2018.09.016},
  file      = {:/home/sd/Documents/papers/ea168eb6d5ea0f637fa554ba6c03ef54.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Chen2019,
  author    = {Mingyou Chen and Yunchao Tang and Xiangjun Zou and Kuangyu Huang and Lijuan Li and Yuxin He},
  journal   = {Optics and Lasers in Engineering},
  title     = {High-accuracy multi-camera reconstruction enhanced by adaptive point cloud correction algorithm},
  year      = {2019},
  month     = {nov},
  pages     = {170--183},
  volume    = {122},
  doi       = {https://doi.org/10.1016/j.optlaseng.2019.06.011},
  file      = {:/home/sd/Documents/code/mas-ws-20/assignments/isw/glossary/glossary.bib.sav:;:/home/sd/Documents/papers/chen2019.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Kusumam2017,
  author    = {Keerthy Kusumam and Tom{\'{a}}{\v{s}} Krajn{\'{\i}}k and Simon Pearson and Tom Duckett and Grzegorz Cielniak},
  journal   = {Journal of Field Robotics},
  title     = {3D-vision based detection, localization, and sizing of broccoli heads in the field},
  year      = {2017},
  month     = {jun},
  number    = {8},
  pages     = {1505--1518},
  volume    = {34},
  doi       = {https://doi.org/10.1002/rob.21726},
  file      = {:/home/sd/Documents/papers/kusumam2017.pdf:PDF},
  publisher = {Wiley},
}

@Article{Zhao2016,
  author    = {Yuanshen Zhao and Liang Gong and Yixiang Huang and Chengliang Liu},
  journal   = {Computers and Electronics in Agriculture},
  title     = {A review of key techniques of vision-based control for harvesting robot},
  year      = {2016},
  month     = {sep},
  pages     = {311--323},
  volume    = {127},
  doi       = {https://doi.org/10.1016/j.compag.2016.06.022},
  file      = {:/home/sd/Documents/papers/zhao2016.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Wong2018,
  author    = {Cuebong Wong and Erfu Yang and Xiu-Tian Yan and Dongbing Gu},
  journal   = {Systems Science {\&} Control Engineering},
  title     = {Autonomous robots for harsh environments: a holistic overview of current solutions and ongoing challenges},
  year      = {2018},
  month     = {jan},
  number    = {1},
  pages     = {213--219},
  volume    = {6},
  doi       = {https://doi.org/10.1080/21642583.2018.1477634},
  file      = {:/home/sd/Documents/papers/wong2018.pdf:PDF},
  publisher = {Informa {UK} Limited},
}

@Article{Arai2002,
  author    = {Arai, Tamio and Pagello, Enrico and Parker, Lynne E and others},
  journal   = {IEEE Transactions on robotics and automation},
  title     = {Advances in multi-robot systems},
  year      = {2002},
  number    = {5},
  pages     = {655--661},
  volume    = {18},
  file      = {:/home/sd/Documents/papers/10.1.1.14.4710.pdf:PDF},
  publisher = {Citeseer},
}

@Comment{jabref-meta: databaseType:bibtex;}
