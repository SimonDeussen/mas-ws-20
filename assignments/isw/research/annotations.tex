\documentclass{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{apacite}

\title{MAS ISW Reading Reports}
\date{26.01.2021}
\author{Simon Deussen}

\begin{document}
\pagenumbering{gobble}
\maketitle
\pagenumbering{arabic}

\tableofcontents
\newpage

% ================= TEMPLATE =================
% \section{Reading Report: \emph{TITLE}}
% \cite{}

% \subsection*{Abstract}

% \subsection*{Keywords}

% \subsection*{Questions}
% \subsubsection*{What are the motivations for this work?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What is the proposed solution?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What is the work`s evaluation of the solution?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What are the contributions?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What are the future directions of the research?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What questions have I left?}
% \begin{itemize}
%     \item 
% \end{itemize}
% \subsubsection*{What is my main take away from this paper?}
% \begin{itemize}
%     \item 
% \end{itemize}

% \subsection*{Summary}

% \subsection*{Rating}

% ================= TEMPLATE =================

\section{Reading Report: \emph{Analysis of Dynamic Task Allocation in Multi-Robot Systems
}}
\cite{Lerman2006}

\subsection*{Abstract}
Dynamic task allocation is an essential requirement for multi-robot
systems operating in unknown dynamic environments. It allows
robots to change their behavior in response to environmental changes
or actions of other robots in order to improve overall system performance. Emergent coordination algorithms for task allocation that
use only local sensing and no direct communication between robots
are attractive because they are robust and scalable. However, a lack
of formal analysis tools makes emergent coordination algorithms
difficult to design. In this paper we present a mathematical model
of a general dynamic task allocation mechanism. Robots using this
mechanism have to choose between two types of tasks, and the goal
is to achieve a desired task division in the absence of explicit communication and global knowledge. Robots estimate the state of the
environment from repeated local observations and decide which task
to choose based on these observations. We model the robots and observations as stochastic processes and study the dynamics of the collective behavior. Specifically, we analyze the effect that the number
of observations and the choice of the decision function have on the
performance of the system. The mathematical models are validated
in a multi-robot multi-foraging scenario. The model’s predictions
agree very closely with results of embodied simulations.

\subsection*{Keywords}
emergent coordination, mathematic analysis, foraging, multi-robot systems, distributed mrs, implicit communication

\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item Dynamic task allocation is necessary in unknown dynamic environments. When working with multiple robots, communications bottlenecks can occur fast. To combat this, emergent coordination algorithms without global knowledge are viable solutions and able to scale much better as explicit communication.
    \item Using only local sensing without communication makes the system behave unpredictable. For prediction of the multi-robot systems behavior, the authors present several formal analysis tools. 
    \item Distributed multi-robot systems are interesting because they exhibit better scalability and robustness against robot failures and environment changes. 
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item The authors created mathematical models for simple multi-robot coordination without communication and global knowledge. After the proposed formal models they validated them experimentally using a simulation.
    \item The authors used a simple example of two different kinds of task and robots which will passively signal which kind of task they are currently doing. Based on local sensing each robots evaluates independently which of the two task it should follow. This toy problem got modelled using  stochastic methods.
    \item Using global knowledge and communication the fractions of robots doing task one or task do respectively should be close to the fractions of the total amount of booth task types. Using the proposed models and the experimental evaluation the authors show that the robots are able to come close to this ideal fractions.
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors state that \emph{"The agreement between theoretical and experimental results is excellent."}. 
    \item Besides predicting of the average collective behavior of the robots, they can also characterize the fluctuations in the systems.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The problem showcased by the authors is quite simple, but the formal methods should hold up to more complex systems.
    \item The comparison of the simulation results with the formal models is sound. 
    \item I think the simple methods used for passive displaying of the task could be improved in such a way that they also work in real world environments - but Nevertheless I think it is better to combine this emergent control system with  global control methods and communication.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item A formal analysis creating models to predict the behavior in multi-robot systems with dynamic task allocation and no explicit communication between the robots. The mathematical models are able to predict the task allocation and changes in system states for a simple foraging toy problem.
    \item The author validated the models using a simulation.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item Future research should include higher number of different tasks, as well as changing the number and density of tasks and robots dynamically during the experiments.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item Using local sensing and limited  information exchange between the robots can dynamically allocate task in an efficient way between robots. Even by using simple systems it works surprisingly well.
    \item I am still torn between the need to do such in-depth mathematic modelling or just relying on the empirical data from the experiments. On the one hand, one can gain deep insights into the working of the behavior, but on the other hand, modelling more complex situation will quickly become too hard.
\end{itemize}

\subsection*{Summary}
This paper is a solid base for the mathematic modelling of emergent behavior.  
\subsection*{Rating}
4/5


\section{Reading Report: \emph{A comprehensive taxonomy for multi-robot task allocation}}
\cite{Korsah2013}

\subsection*{Abstract}
Task allocation is an important aspect of many multi-robot systems. The features and complexity of multi-robot task allo-
cation (MRTA) problems are dictated by the requirements of the particular domain under consideration. These problems
can range from those involving instantaneous distribution of simple, independent tasks among members of a homogenous
team, to those requiring the time-extended scheduling of complex interrelated multi-step tasks for members of a heteroge-
nous team related by several constraints. The existing widely used taxonomy for task allocation in multi-robot systems was
designed for problems with independent tasks and does not deal with problems with interrelated utilities and constraints.
While that taxonomy was a ground-breaking contribution to the MRTA literature, a survey of recent work in MRTA reveals
that it is no longer a sufficient taxonomy, due to the increasing importance of interrelated utilities and constraints in
realistic MRTA problems under consideration. Thus, in this paper, we present a new, comprehensive taxonomy, iTax, that
explicitly takes into consideration the issues of interrelated utilities and constraints. Our taxonomy maps categories of
MRTA problems to existing mathematical models from combinatorial optimization and operations research, and hence
draws important parallels between robotics and these fields.

\subsection*{Keywords}
multi-robot coordination, task allocation, taxonomy

\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item The authors want to extend the commonly used MRTA taxonomy from Gerkey \cite{Gerkey2004} with the dimension of interrelatedness of given task. 
    \item Different task can be decomposed and related with each other. To capture this, a classification along the degrees between single or atomic tasks, and complex task is needed.
    \item The authors found the increasing importance of interrelated and complex tasks as a basis to crate this new and more complex taxonomy.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
  \item The authors created a taxonomy for MRTA problems along the degree of interrelatedness of tasks. Following classes are presented: \ 
  \begin{description}
      \item[No Dependencies class (ND)] The utility of an agent only depends on the agent and the task itself. No other dependencies. 
      \item[In-schedule Dependencies (ID)] The agents effective utility depends on the other task it is assigned to. The schedule how the tasks are executed gets relvant.
      \item[Cross-schedule Dependencies (XD)] Here the utility of the agents not only depend on their one schedule but also the schedule of all the other agents. Until here, all task have been elemental, simple or compound tasks.
      \item[Complex Dependencies (CD)] It is not just relevant \emph{who} and \emph{when} each task should be executed, but on the same time the \emph{decomposition} of any given task also depends on the schedule of all other tasks and agents. (Complex tasks)
      \item[Elemental task]  An task, which can not be decomposed any further.
      \item[Simple task]  An task, which is either elemental or can be decomposed into elemental tasks.
      \item[Compound task] A task which can be decomposed in exactly one fixed set of simple subtasks.
      \item[Comlplex task] This task can be decomposed into multiple different subsets, where at least one subset requirers multi agent comporation.
  \end{description}
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item Even though it is more complex than the standard taxonomy from Gerkey, they find it still comprehensive and relevant. 
    \item With the new classes the authors find it is much easier to forsee the computational complexity of given problems.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The new degree of interrelatedness is a valid measure to compare the difficulty of tasks. 
    \item Two categories contain most of the relevant work and examples, so I wonder if the separation into four classes is needed, or if the two classes ND and XD would have been enough for practical reasoning. 
    \item Since MRTA problems in the ND class are still solvable in polynomial time, and the remaining are all NP-hard, with no out-of-the-box solutions, this could be enough. But the overall distinguishing makes somewhat sense of course, but most real tasks fall in the XD category anyways.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item The author created an in-depth taxonomy which highlights a new key dimension, the degree of interrelatedness if tasks and constraints.
    \item Using this new taxonomy the authors showcase relevant mathematical models for each problem class.
    \item They used many parts of Gerkeys taxonomy and relate all of their new found classes to the standards. 
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item None, explicit. 
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item I wonder if there is another, newer taxonomy build on top of this.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item Great in-depth taxonomy of relevant problems in MRTA.
\end{itemize}

\subsection*{Summary}
This paper is an excellent building block of my seminar report!
\subsection*{Rating}

\section{Reading Report: \emph{Multi-robot Task Allocation: A Review of the State-of-the-Art}}
\cite{Khamis2015}

\subsection*{Abstract}
Multi-robot systems (MRS) are a group of robots that are designed
aiming to perform some collective behavior. By this collective behavior, some goals
that are impossible for a single robot to achieve become feasible and attainable.
There are several foreseen benefits of MRS compared to single robot systems such
as the increased ability to resolve task complexity, increasing performance, relia-
bility and simplicity in design. These benefits have attracted many researchers from
academia and industry to investigate how to design and develop robust versatile MRS
by solving a number of challenging problems such as complex task allocation, group
formation, cooperative object detection and tracking, communication relaying and
self-organization to name just a few. One of the most challenging problems of MRS
is how to optimally assign a set of robots to a set of tasks in such a way that optimizes
the overall system performance subject to a set of constraints. This problem is known
as Multi-robot Task Allocation (MRTA) problem. MRTA is a complex problem
especially when it comes to heterogeneous unreliable robots equipped with different
capabilities that are required to perform various tasks with different requirements
and constraints in an optimal way. This chapter provides a comprehensive review on
challenging aspects of MRTA problem, recent approaches to tackle this problem and
the future directions.

\subsection*{Keywords}
Multi-robot Task Allocation, Optimization based approach, market based approach, distribution, cooperation

\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item The authors state that using multu robot systems (MRS) help solving problems with following benefits: \ \begin{itemize}
        \item Resolving task complexity: Some task can be achieved easier in a group than in a single system.
        \item Increasing performance: If tasks can be parallelizes, the performance improves dramatically.
        \item Increasing reliability: Having multiply actors increases redundancy and robustness for less failures.
        \item Simplicity in design: Multiple small and simple robots should be easier to build than big mighty machines.
    \end{itemize}
    \item The authors further state the MRTA is the hardest problem in MRS. To solve this, many different research approaches have been done, and the authors want to capture the state of the art.
\end{itemize}

\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item This a in-depth review of current (2015) work in the field of MRTA. 
    \item The papers showcase several ways to model the MRTA problem mathematically. Including: \begin{itemize}
        \item ALLIANCE efficiency problem (AEP)
        \item Optimal assignment problem (OAP)
        \item Multiple traveling salesman problem (mTSP)
        \item Discrete fair division
    \end{itemize}
    \item For deeper understanding the authors classified MRTA schemes similar to \cite{Gerkey2004}.
    \item The crux of MRTA are the organizational paradigms for the communication between the actors. The authors distinguish between \emph{centralized approaches} and \emph{decentralized approaches}. Several papers are mentioned here for further research into the state-of-the-art.
\item The last parts are a comparison of \emph{market-based approaches} versus \emph{optimization-based approaches}. 
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors claim to have cpatures the current (2015) state-of-the-art of MRTA.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item While the paper has a good beginning, with many helpful links, reviews and pointer to other research, the ending is underwhelming. It feels like the paper stops half-way trough. 
    \item Marked-based approaches are still described and reviews in-depth, but after this suddenly details and structure starts missing.
    \item The conclusion has no real content or ending.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item Review of different techniques, methods and algorithms for multiple robot task assignment problems.
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item Why did they stop writing the paper? The start and the first couple of reviews haven been useful.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item Simulated annealing MRTA strategies tend to perform the best in small-, medium- and large-scale problems. For best capabilities matching market-based approaches are better.
\end{itemize}

\subsection*{Summary}
Good explanation of several algorithms and approaches for solving task assignment problems. But the ending is bad.
\subsection*{Rating}
2/5

\section{Reading Report: \emph{A Formal Analysis and Taxonomy of Task Allocation in Multi-Robot Systems
}}
\cite{Gerkey2004}

\subsection*{Abstract}
Despite more than a decade of experimental work in multi-robot
systems, important theoretical aspects of multi-robot coordination
mechanisms have, to date, been largely untreated. To address this
issue, we focus on the problem of multi-robot task allocation (MRTA).
Most work on MRTA has been ad hoc and empirical, with many
coordination architectures having been proposed and validated in a
proof-of-concept fashion, but infrequently analyzed. With the goal of
bringing objective grounding to this important area of research, we
present a formal study of MRTA problems. A domain-independent
taxonomy of MRTA problems is given, and it is shown how many
such problems can be viewed as instances of other, well-studied,
optimization problems. We demonstrate how relevant theory from
operations research and combinatorial optimization can be used for
analysis and greater understanding of existing approaches to task
allocation, and to show how the same theory can be used in the
synthesis of new approaches.

\subsection*{Keywords}
task allocation, multi-robot systems, coordination, utility


\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item For many problems exist better solution using multiple robots instead of a single system. But as soon as multiple actors are involved, there is a need for coordination, collaboration and cooperation. This emerges in the field of multi-robot task allocation (MRTA).
    \item With more and more research in multi robot systems, the authors recognized a need for a formal taxonomy for comparison of different approaches. 
    \item The authors say, most reseach efforts in MRS focus heavily on the building and validation of somewhat working systems. Missing here is a methodology to compare the approaches between each other and recommend algorithms for each problem class.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item The authors recommend a general taxonomy for classifying MRTA problems and suggest formal algorithms for each classes.
    \item The taxonomy is build along following axis:\ \begin{itemize}
        \item Single-task robots (ST) versus multi-task robots (MT)
        \item Single-robot tasks (SR) versus multi-robot tasks (MR)
        \item Instantaneous assignment (IA) versus time-extended assignment (TA):
    \end{itemize}
    \item This results in following problem classes: \ \begin{itemize}
        \item ST–SR–IA: Single-Task Robots, Single-Robot Tasks, Instantaneous Assignment
        \item ST–SR–TA: Single-Task Robots, Single-Robot Tasks, Time-Extended Assignment
        \item ST–MR–IA: Single-Task Robots, Multi-Robot Tasks, Instantaneous Assignment
        \item ST–MR–TA: Single-Task Robots, Multi-Robot Tasks, Time-Extended Assignment
        \item MT–SR–IA and MT–SR–TA: Multi-Task Robots, Single-Robot Tasks
        \item MT–MR–IA: Multi-Task Robots, Multi-Robot Tasks, Instantaneous Assignment        
        \item MT–MR–TA: Multi-Task Robots, Multi-Robot Tasks, Time-Extended Assignment
    \end{itemize}
    \item Each of those formal classes is evaluated in computational and communication requirements as well as the solution quality.
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors point out, this is a corse and general taxonomy. Its goal is to find comparisons and classifications on a high level. The proposed algorithms can work in some ways, but should be seen as a baseline for comparing to engineered solutions using domain specific knowledge.  
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The need for formal constraints to analyse research in MRS its important. This shows similarities, differences and leaps in existing and future work.
    \item I think the seven presented classes are a good way to differentiate between problem cases.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item A formal taxonomy
    \item Comparison between 6 recent (2004) research topics
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item The most needed research direction are of course better heuristic algorithms to solve all of the optimization problems occurring in MRTA.
    \item It is possible to create a more specific taxonomy using domain specific knowledge for different fields.
    \item Another approach is using the high-dimensional utility landscape to classify different MRTA problems.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item The approach using economic and organizational tools to certain problems in robotic communication. 
    \item Task assignment is a major part in any distributed system, the paper showed interesting solution approaches.
\end{itemize}

\subsection*{Summary}
Good taxonomy, will be a major part of the MRS section of the seminar report.
\subsection*{Rating}
5/5




\section{Reading Report: \emph{Advances in Multi-Robot Systems}}
\cite{Arai2002}

\subsection*{Abstract}
As research progresses in distributed robotic systems, more and more aspects of multi-robot systems are being
explored. This special issue on Multi-Robot Systems provides
a broad sampling of the research that is currently ongoing in
the field of distributed mobile robot systems. To help categorize this research, we have identified seven primary research top-
ics within multi-robot systems — biological inspirations, communication, architectures, localization/mapping/exploration, object
transport and manipulation, motion coordination, and reconfigurable robots. This editorial examines these research areas and
discusses the special issue articles in this context. We conclude by
identifying several additional open research issues in distributed
mobile robotic systems.


\subsection*{Keywords}
Distributed robotics, survey, cooperative robotics, multi-robot systems



\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item The main motivations for the authors is to categorize recent (2002) research in the field of multi-robot systems (MRS) and give an in-depth overview.
    \item MRS are proven to be often more efficient and more fault tolerant than single robots. 
    \item Cooperation in robots is a emerging field and needs much additional research.
    \item It is usually cheaper to solve a problem with multiple simple robots instead of one big robot.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item The authors identified those seven categories of recent research: \ 
    \begin{itemize}
        \item Biological inspiration
        \item Communication
        \item Architecture, task allocation and control
        \item Localization, mapping, and exploration
        \item Object transport and manipulation
        \item Motion coordination 
        \item Reconfigurable robots
    \end{itemize}
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item Following recent work has been done in the categories: \
    \begin{description}
        \item[Biological inspiration] \ 
        \begin{itemize} 
            \item The current (2002) trend is to use behavior driven control (BDC).
            \item BDC is the using of using social characteristics of insects like bees or ants for controlling robots.
            \item Using those approaches MRS can flock, disperse, aggregate, forage and follow trails.
            \item Another direction is trying to imitate the behavior of higher animals like wolf packs or predator-prey systems.
            \item Robot soccer is also a domain where the behavior is biologically inspired: Here from humans. Role distribution and acting are keywords here.
        \end{itemize}
        \item[Communication] \ 
        \begin{itemize} 
            \item Studies on implicit and explicit communication both show advantages for MRS. 
            \item Implicit communications is through the world and through behavior - an human example could be body language.
            \item Explicit communication is using an dedicated channel for sending particular messages between the actors.
            \item Using distributed communication networks can improve fault tolerance and availability. Here lies a key topic: How can multiple robots work together if the communication channel is not available all the time and fails unexpectedly?
            \item More research is also done in using a shared channel for process scheduling in low compute nodes.
        \end{itemize}
        \item[Architecture, task allocation and control] \ 
        \begin{itemize} 
            \item This topics are key aspects in MRS and holds some of the hardest problems: \
            \begin{itemize}
                \item Action selection
                \item Delegation of authority and control
                \item Communication structure
                \item Heterogeneity versus homogeneity of robots
                \item Achieving coherence amidst local actions
                \item Resolving of conflicts
            \end{itemize}
            \item One approach is an proxy processing scheme for remote computation
            \item Using multiple layers of abstraction for control is another idea. Layers include here the robot control level, group level, object control level and task control.
            \item There are even papers using an emotion based control for MRS.
            \item Using a currency as a control architecture for resource allocation gets also investigated in mentioned research.
            \item Other research uses multiple planners for priority based task assignment and motion planning.
        \end{itemize}
        \item[Localization, mapping, and exploration] \ 
        \begin{itemize} 
            \item For single robots exists already an extensive amount of research for mapping and exploration. Adapting this library of knowledge for MRS is only a fairly recently trend.
            \item New algorithms got developed taking advantages of the mapping capabilities of multiple robots. Groups of robots can sense and localize simultaneously resulting in higher accuracy than only a single robot.
            \item Localizing their team members visually is also an important topic for multi robot cooperation.
            \item The last mentioned research topic is to enable a robotic team to navigate in an unknown environment using landmarks and following waypoints.
        \end{itemize}
        \item[Object transport and manipulation] \ 
        \begin{itemize} 
            \item Using MRS to manipulate a object cooperatively is a long standing, but hard to reach goal.
            \item More feasible, than having mutiple robots grip an object, is to push objects around using formation control approaches.
            \item I think more current reseach (newer than from 2002) will have more progress here.
        \end{itemize}
        \item[Motion coordination ] \ 
        \begin{itemize} 
            \item Topics in motion coordination include: \
            \begin{itemize}
                \item Multi-robot path planning
                \item Traffic control
                \item Formation generation
                \item Formation keeping 
                \item Target tracking
                \item Target search 
                \item Multi-robot docking
            \end{itemize}
            \item Here, the presented research are systems to scout using UGV and dynamic priority assignments. Here the goal is to track multiple objects in a cluttered environment.
            \item Another approach makes the robots track one special \emph{friend} for advanced formation control. Here the robots should maintain a desired angle and distance in between them.
            \item Decentralized motion coordination efforts can be used for perimeter security.
        \end{itemize}
        \item[Reconfigurable robots] \ 
        \begin{itemize} 
            \item This topic studies modular robots which can connect in different ways into a specific shape.
            \item Most studies sofar have been simulation only, but there are some research with physical robots in a worm-like or spider-like configuration.
        \end{itemize}
    \end{description}

\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The seven chosen categories are on point. Even 20 years later those categories remain.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item Great, in-depth snapshot of the current (2002) state of the art. The authors explain the categories and the mentioned research very well.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item In each of the categories the research goes much further now. This question does not rely apply.
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item Reconfigurable robots sounds super interesting, i might have to study some papers about current capabilities.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item This paper is good basis to compare the progress of the last 20 years to. Roboticists in 2002 struggled with the same problems as now. Of course we have stronger computers now, but the problems in control, distribution and communication remain.
\end{itemize}

\subsection*{Summary}
Great, in-depth snapshot of the current (2002) state of the art. The authors explain the categories and the mentioned research very well.
But quite dated (2002). Good basis and good for comparison.

\subsection*{Rating}
3/5


\section{Reading Report: \emph{Using color and 3D geometry features to segment fruit point cloud and improve fruit recognition accuracy}}
\cite{Wu2020}

\subsection*{Abstract}
Fruit image segmentation is an essential step to distinguish fruits from the background. In order to improve the
fruits recognition accuracy for harvesting robots in three-dimensional (3D) space, a method with the fusion of
color and 3D geometry features for fruit point cloud segmentation was proposed in this study. The local de-
scriptor was applied to obtain the candidate regions, and the global descriptor was used to obtain the final
segmented results. Firstly, the hue, saturation, value (HSV) color features and normal orientation features of
pixels were fused to obtain the preliminary segmentation results. Then, the pre-processed color image and depth
image were converted to a point cloud, and it was clustered into multiple regions by the Euclidean clustering
algorithm. Finally, we utilized the viewpoint feature histogram (VFH) of each point cloud cluster to remove the
remaining non-fruit regions. The experiments showed that the segmentation accuracy of the proposed method
was 98.99\%, and the precision was 80.09\%, which are both superior to the traditional color segmentation
methods. In addition, a fruit detection method based on shape analysis showed that it is more effective in
improving fruit recognition rate and reducing false detection rate than the color segmentation methods.

\subsection*{Keywords}
Fruit recognition, Point cloud, Geometry feature, Local descriptor, Global descriptor

\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item The main motivation for using agricultural robots is cost reduction by saving labor costs.
    \item Fruit recognition ist the basis of proper robotic harvesting. Without a high recognition accuracy there is no high harvesting success rate feasible.
    \item Most fruit recognition approaches use only color information fir finding the fruits. Those approaches are ineffective under real world conditions because they fail under certain light conditions and low contrast. 
    \item Here the authors want to improve detection rates by including depth information using a \emph{Microsoft Kinect 2.0} .
    \item The authors claim that using the additional 3D data the resulting algorithms should be more robust and fit for the real world.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item Using a \emph{Microsoft Kinect 2.0} camera which can simultaneously capture color and depth image as well as point cloud data, the authors propose an algorithm to segment fruit and non-fruit regions in the captured data.
    \item The authors first transform the RGB color data into HSV format, then they extract color features and normal orientation features from depth information for a combined feature vector for classification using a support vector machine.
    \item After the classification it is now possible to remove all non-fruit regions.
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors evaluated different feature sets to be able to compare themselves against other studies. They basically created labelled data for training and testing and compared the classification results resulting from different feature sets. The best results come from using the color information as HSV data and using the 3D information as normal orientation. 
    \item With the presented method they were able to classify pixels into fruit and non-fruit regions with an accuracy of 97.55\%. 
    \item The authors noted that this method is more robust in cases of occlusion or harsh light conditions than methods only utilizing image data. They also were able to remove more background area from fruits than older approaches.
    \item But they tried to avoid strong sunlight because the \emph{Kinect} stops working properly if its too bright.
    \item The biggest downside they mentioned was that they needed \textbf{60 seconds processing time} per image. (but they did use matlab...)
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The idea of using \emph{Kinect} cameras to gather more information than just RGB data is great. I do not think that harvesting robots in the future will be able to only use 2D data to navigate itself and their end-effectors in complex environments like orchards, greenhouses and fields.
    \item The methodology used to determined the best feature set is clear and concise - so I would trust their results.
    \item My biggest disappointment is that they did not show any code at all. It is obvious from the results, that their matlab code has to be really bad because they have a runtime of 60 seconds. Using a proper programming language will improve their results drastically.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item They contributed an algorithm to classify image plus depth data from \emph{Kinect} into fruit and non-fruit regions. Here the authors used peaches. 
    \item The algorithm works in multiple stages, generating feature sets from different transformed data and finally classifying each pixel into one of the two classes.
    \item Using the same classifier they tested different feature sets to show each classification accuracy. From here future work can see which features to avoid or use.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item In their next study they want to reduce the influence of light conditions and variations to the classification. 
    \item Another point is to use more effective 3D features to assist the point cloud segmentation.
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item This kind of papers always profit from having their code open source. I would like to see their data pipelines and scripts to figure out why they needed 60 seconds.
    \item I still do not understand the Normal Orientation algorithm, but this should be fine for now.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item My hypothesis, that it can not work to just use 2D features for recognizing and localizing fruits is validated.\
    \item The  authors used quite simple 3D features but they could improve significantly over not using them. 
\end{itemize}

\subsection*{Summary}
Cool paper over the algorithmic side of finding fruits.  Unfortunately no code at all but the general directions of their approach are clear.

\subsection*{Rating}
4/5



\section{Reading Report: \emph{A review of key techniques of vision-based control for harvesting robot}}
\cite{Zhao2016}

\subsection*{Abstract}
Although there is a rapid development of agricultural robotic technologies, a lack of access to robust fruit
recognition and precision picking capabilities has limited the commercial application of harvesting
robots. On the other hand, recent advances in key techniques in vision-based control have improved this
situation. These techniques include vision information acquisition strategies, fruit recognition algo-
rithms, and eye-hand coordination methods. In a fruit or vegetable harvesting robot, vision control is
employed to solve two major problems in detecting objects in tree canopies and picking objects using
visual information. This paper presents a review on these key vision control techniques and their poten-
tial applications in fruit or vegetable harvesting robots. The challenges and feature trends of applying
these vision control techniques in harvesting robots are also described and discussed in the review.


\subsection*{Keywords}
Harvesting robot, Vision-based control, Vision information acquisition, Fruit recognition, Eye-hand coordination


\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item The authors claim that the recognition and the localization of fruits is the biggest bottleneck in harvesting.
    \item Because of the complex loosely structured nature of the agricultural domain, vision-based control is the only possibility.
    \item Each fruit hangs or lies in a random location which makes it necessary to continually find the fruits. 
    \item The recognition and localization is the foundation of successful harvesting. So this is the first thing which has to wokr in order to get commercial harvesting robots. 
    \item All in all this papers wants to give an overview over current (2016) techniques to identify fruits in plants.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item This papers reviews current and older approaches in following categories of vision schemes:
    \begin{itemize}
        \item Monocular camera scheme
        \item Binocular camera scheme
        \item Laser active visual scheme
        \item Thermal imaging scheme
        \item Spectral imaging scheme
    \end{itemize} 
    \item Another part of the review are recognition approaches, those are classified in:
    \begin{itemize}
        \item Single feature analysis
        \item Multi feature analysis
        \item Pattern recognition 
    \end{itemize}
    \item The last part of the paper analyses two different ways for the \emph{eye-hand} coordination:
    \begin{itemize}
        \item Open-loop visual control
        \item Visual servo control
    \end{itemize} 
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item Because this work is a review, I will write down and highlight the papers findings in each category:
    \begin{description}
        \item[Monocular camera scheme] \ 
        \begin{itemize} 
            \item This is a classical and cheap approach to recognition. The biggest problem is of course getting 3D coordinates from 2D data.
            \item Recognition rates are between 75\% (2005) and 96\% (2011). 
         \end{itemize}
        \item[Binocular camera scheme] \ 
        \begin{itemize} 
            \item Using two different calibrated cameras are able to not just get color information but directly create 3D coordinates using triangulation.
            \item Recognition rates are also in the 90\% area. 
            \item A system developed 2004 could reliable detect apples with an error of  less than 20mm in a distance between 400 and 1500mm.
         \end{itemize}
        \item[Laser active visual scheme] \ 
        \begin{itemize} 
            \item By using laser scanners to obtain 3D geometry it is possible to have much higher positional accuracy.
            \item Different sensors work with different kinds of lasers. By combining different wave lengths it is even possible to detect fruits by spectral reflections.
            \item Newest data from 2015 shows an accuracy of 97.5\% for finding apples with an 3D reconstruction technique.
         \end{itemize}
        \item[Thermal imaging scheme] \ 
        \begin{itemize} 
            \item Infrared radiation from plants can make it easier to distinguish from fruits and other plant parts. Leaves and such accumulate less heats than the fruits.
            \item Studies in 2008 have shown that citrus fruits are consistent 1 °C warmer than other objects.
         \end{itemize}
        \item[Spectral imaging scheme] \ 
        \begin{itemize} 
            \item Spectral cameras are using special wave length to create more contrast between the fruits and leaves. When looking for green crops this approach can be better than using a traditional camera.
            \item This technique also got accuracies around 90\%.
         \end{itemize}
        \item[Single feature analysis] \ 
        \begin{itemize} 
            \item This way of image-analysis uses only one feature like color, shape, and texture.
            \item For fruits which have a different color than the other plant parts, using color this a viable approach.  
            \item It is also possible to look for shapes, but this approach has more problems with clusters and occlusions.
            \item Accuracy's of 95+\% are reported. 
            \item This is computational cheaper than using multi-features
         \end{itemize}
        \item[Multi feature analysis] \ 
        \begin{itemize} 
            \item In order to increase detection, reliability and robustness, multiple feautres from an image can be used to detect and localize the fruits.
            \item Using multiple features increases algorithmic complexity. This needs better processors to compute in an appropriate time.
            \item Interestingly this review shows \emph{worse} results here, but still in the area of 90\%.
         \end{itemize}
        \item[Pattern recognition ] \ 
        \begin{itemize} 
            \item The pattern recognition approach uses even more complex algorithms to find the fruits. 
            \item Examples are statistical models, clustering, artificial neural networks, support vector machines and fuzzy patern recognition.
            \item Here the papers gets worse and worse, no real value besides the pointers to the mentioned papers.
         \end{itemize}
        \item[Open-loop visual control] \ 
        \begin{itemize} 
            \item In an open-loop control mode, the sensors will first detect the positions and then the manipulator will move to estimated positions.
            \item Without feedback, this system will fail as soon as wind or the manipulators displace the fruits.
            \item The authors mentioned system where first the manipulators gets placed fast using open-loop control in the vincinity then uses visual servo for fine positioning for grasping the fruits.
         \end{itemize}
        \item[Visual servo control] \ 
        \begin{itemize} 
            \item This mode uses feedback between the manipulator and the sensors to continually adjust the position. This needs a fixed loop between control, computation, manipulators and sensors.
            \item This approach is slower but also more accurate.
            \item Generally speaking i think this or a combination of both control modes make the most sense.
         \end{itemize}
    \end{description}
\end{itemize} 
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item Vision based system to recognize and localize fruits are needed to make harvesting by robots work. Because the environment is complex and the plants chaotic finding the position of the fruits is really hard.
    \item The authors describe many ways to exploit some characteristics of the fruits for an easy recognition. But all of those approaches are in my opinion shortcuts which do not really work.
    \item I think more complex models of the plants are needed to build robots which are able to work in real-world conditions in the industry.
    \item Of course some of the exploits can help, but the robots must have to work with 3D geometry otherwise the performance will always be worse than the one of humans. 
    \item Occlusion and low contrast have to be part of the models of the robots.
    \item This will need high computational power.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item This review shows some key aspect of the computer vision problems of harvesting. 
    \item The authors created categories of important aspects and showcased work in those.
    \item The authors \textbf{did not} create a systematic approach to compare the results of papers. For example did they show higher accuray for single feature analysis than multi feature analysis or pattern recognition. Which does not make sense.
    \item The authors also did not say anything about computational costs.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item Besides improving the current algorithms and sensor technologies, the authors talked about more coming research in following areas: \begin{itemize}
        \item Human-machine interaction
        \item Multi-arm robots
        \item Improving Greenhouse environments for robots.
    \end{itemize}
\end{itemize}

\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item Current vision systems need to use some kind of exploit or trick to find the fruits. (Tomatoes are redder than the leaves) 
    \item While this of course an important feature, all approaches lack a model of the plants based on their real 3D geometry. 
    \item Because of this all robotic systems using those approaches will only be able to pick the best and easiest to see fruits but nothing hidden behind leaves. As long as it is not possible to use a geometry based solution i do not think that robots are viable for agriculture.
\end{itemize}

\subsection*{Summary}
Good pointers to deeper research but no good comparison between papers. No deeper methodology, also not written in a good way.
\subsection*{Rating}
2/5


\section{Reading Report: \emph{Development of a sweet pepper harvesting robot}}
\cite{Arad2020}

\subsection*{Abstract}
This paper presents the development, testing and validation of SWEEPER, a robot for
harvesting sweet pepper fruit in greenhouses. The robotic system includes a six
degrees of freedom industrial arm equipped with a specially designed end effector,
RGB‐D camera, high‐end computer with graphics processing unit, programmable logic
controllers, other electronic equipment, and a small container to store harvested
fruit. All is mounted on a cart that autonomously drives on pipe rails and concrete
floor in the end‐user environment. The overall operation of the harvesting robot is
described along with details of the algorithms for fruit detection and localization,
grasp pose estimation, and motion control. The main contributions of this paper are
the integrated system design and its validation and extensive field testing in a
commercial greenhouse for different varieties and growing conditions. A total of 262
fruits were involved in a 4‐week long testing period. The average cycle time to
harvest a fruit was 24 s. Logistics took approximately 50\% of this time (7.8 s for
discharge of fruit and 4.7 s for platform movements). Laboratory experiments have
proven that the cycle time can be reduced to 15 s by running the robot manipulator at
a higher speed. The harvest success rates were 61\% for the best fit crop conditions
and 18\% in current crop conditions. This reveals the importance of finding the best fit
crop conditions and crop varieties for successful robotic harvesting. The SWEEPER
robot is the first sweet pepper harvesting robot to demonstrate this kind of
performance in a commercial greenhouse.


\subsection*{Keywords}
agriculture, computer vision, field test, motion control, real‐world conditions, robotics


\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item Working in greenhouses is a extrem unfriendly environment with boring and repetitive tasks. Finding skilled
    labor for this get harder and harder every year. Because of this automated and commercially viable automations are needed.
    \item To make harvesting robots commercially viable it is needed to improve the harvesting performance and speed in real-world conditions.
    \item This papers shows how one current state-of-art robot performs under realistic conditions.
    \item Of course the main goal of having robots harvest in greenhouses is cost reduction, quality increase and 
    better predictability.
    \item Other harvesting robot have cycle times around 33 seconds per fruit. Here the authors want to improve the state-of-art with better results.
    \item The authors also state, that many research papers lack large-scale experiments, which they want to improve. 
    Maybe they initially wanted to harvest more fruits, but in the end their total harvest was only 262.
    \item Also most other proposed robot solution are too slow or generally bad to be useable in a commercial way.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item In this paper the authors propose a robotic harvesting system for sweet peppers and showcase the testing and validations of its capabilities.
    \item The robots consists of following main components: \begin{itemize}
        \item A standard card driving on rails with a height adjustable platform. 
        \item Six degree of freedom standard industrial arm
        \item Custom build end-effector with a cutter (vibrating knife), sensors and catching mechanism
        \item RGB-D camera 
        \item High-end computer running Ubuntu 14.04 and ROS Indigo with GPU
        \item The whole system is really big! The cart is around four times the length of the arm.
    \end{itemize}
    \item Besides the robot system, the authors also developed algorithms for: \begin{itemize}
        \item Fruit detection
        \item Fruit localization
        \item Grasp pose estimation
        \item Motion control
    \end{itemize}
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors did a very detailed performance evaluation and error analysis. All in all they did 4 weeks of experiments involving 262 peppers of 2 varieties.
    \item On average the robot needed \textbf{24s to harvest a pepper}.
    \item So now comes the bad part: Because real-world conditions are extremely demanding, their systems only managed to
    harvest \textbf{18\% of the peppers}. To make the robot perform better, they removed leaves and fruit cluster and archived 
    a performance of \textbf{61\% successful harvested peppers}.
    \item The main problem with real world conditions are the many occlusions making the detection much harder and often 
    blocking ways of the end-effector to reach the fruits without damaging the plant.
    \item They also proposed to user a smaller end-effector for easier grepping in a a tight environment for future improvements.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The paper, the robot and the analysis of the robots performance are all in-depth and detailed. 
    The robots performance of course is far from being commercial viable.
    \item During the experiments the  authors measured as many parameters manually to get a complete picture of 
    the robots capabilities and shortcomings. (e.g. the paused the robots for each harvesting try to get the relative distance and the angle of the fruits)
    \item Real-world commercially grown pepper plants have a high density and heaps of leaves hiding the fruits. 
    This results in a complex and unstructured geometry making each of the robot`s task even harder
    .\begin{itemize}
        \item The leaves occlude the peppers: The detection and localization needs models which can work with that.
        \item Not only the fruits but also the main stem gets harder to detect which is needed to find the relative position of the fruit and steam for cutting.
        \item The robot has to navigate around the leaves to cut and catch the fruits: Motion planning gets orders of magnitude more complicated. 
    \end{itemize}
    \item With a modification of the crop the detection and harvest rates got much better. This would strongly imply to make the same robot 
    also removes the leaves. I hope they study this topic as well
    \item The authors separeted the whole task in several subtasks and delivered an analysis of every one of their problems. \begin{itemize}
        \item Fruit detection
        \item Fruit researched
        \item Fruit cut
        \item Fruit caught
        \item Fruit placed into container
    \end{itemize}
    \item One of my main doubt is that the authors detected the fruit but not the cutting point. That means they positioned the end-effector 
    relative to the fruit and hoped for the best that the knife will find its correct way to cut off the pepper. This method works okay for them,
    but still this is a area in which they could improve greatly. One of the varieties had longer fruit stems which resulted in a higher failure in the cutting because
    the knife would slide of.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item The authors proposed an integrated system for harvesting sweet peppers.
    \item Besides that they showcased extensive field testing in a commercial greenhouse with partial real-world conditions.
    \item The field testing, error analysis, structure of the paper and methodology are also important contributions.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item One idea was speeding up the robot. In this experiments with scientists around the robot they could not operate on full speed because of safety concerns.
    \item Using a smaller end-effector could result in easier motion planning and better navigation in tight, occluded spaces.
    \item To be able to grep fruits behind leaves it could be feasible to use an arm with an higher degree of freedom. But this would also result in a higher computational cost.
    \item Some parts of the catching mechanism were too stiff which was a source of repeated failures because it has moved parts of the plants away resulting in positioning errors. 
    For this the authors already have a solution planned for the next experiments.
    \item As soon as the system looses sight of a specific fruit the harvesting attempt is cancelled. Including some kind of backtracking will result in a improved harvesting rate.
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item Next to a high-end oc the robot has multiple smaller controllers. I would like to have an in-depth overview over the hardware specs and the components used.
    \item Could the robot use the same end-effector to remove leaves? If so the robot could in the first step prepare every thing for the harvest itself.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item This paper is quite new so I am a bit disappointed in the performance of the state-of-the-art.
    Nevertheless the robot platform and paper is sophisticated and I am sure that with a bit tweaking the performance can improve.
    \item The robots goes to multiple different phases in detection and control modes. Because of this I think the 
    computations are more effecient but on the other hand I seems like it has no proper world and plant model. 
    This results in errors in positioning and the need for occlusion free line of sight to the peppers. 
    \item So the state of the art still relies on simple 2D vision methods for finding its way.  
    This means we need proper ways to model the plants in 3D in an computational effecient form for better motion planning and detection.
\end{itemize}

\subsection*{Summary}
Papers about whole systems with in-depth error and performance analysis are always great. This in particular because it is well written and has a good structure. 
Comeback to this paper and read some of the references!!

\subsection*{Rating}
5/5





\section{Reading Report: \emph{Crop design for improved robotic harvesting: A case study of sweet pepper harvesting}}
\cite{Herck2020}

\subsection*{Abstract}
Current harvesting robots have limited performance, due to the unstructured and dynamic
nature of both the target crops and their environment. Efforts to date focus on improving
sensing and robotic systems. This paper presents a parallel approach, to ‘design’ the crop
and its environment to best fit the robot, similar to robotic integration in industrial robot
deployments.
A systematic methodology to select and modify the crop ‘design’ (crop and environ-
ment) to improve robotic harvesting is presented. We define crop-dependent robotic fea-
tures for successful harvesting (e.g., visibility, reachability), from which associated crop
features are identified (e.g., crop density, internode length). Methods to influence the crop
features are derived (e.g., cultivation practices, climate control) along with a methodo-
logical approach to evaluate the proposed designs. A case study of crop ‘design’ for robotic
sweet pepper harvesting is presented, with statistical analyses of influential parameters.
Since comparison of the multitude of existing crops and possible modifications is impos-
sible due to complexity and time limitations, a sequential field experimental setup is
planned. Experiments over three years, 10 cultivars, two climate control conditions, two
cultivation techniques and two artificial illumination types were performed. Results
showed how modifying the crop effects the crops characteristics influencing robotic har-
vesting by increased visibility and reachability. The systematic crop ‘design’ approach also
led to robot design recommendations. The presented ‘engineering’ the crop ‘design’
framework highlights the importance of close synergy between crop and robot design
achieved by strong collaboration between robotic and agronomy experts resulting in
improved robotic harvesting performance.


\subsection*{Keywords}
Crop design, Harvesting robot, Sweet pepper, Agricultural robotics, Crop engineering, Robot design


\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item One of the main factors limiting the performance of robots in agriculture is the unstructured and dynamic environment. 
    To reduce this, the authors created a case study to \emph{engineer} a improved crop-\emph{design} at the example of sweet peppers.
    \item Similar to using a robot in an industrial environment, a greenhouse should also be optimized towards the robot. Much research works the other way around, but it is important to go both ways.
    \item The authors want to present a systematic methodology to select and modify crops for an improved harvesting.
    \item Improved greenhouse and crop design will directly result in a better performance of the used robotic systems.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item In  this study, the authors they describe experiments run during 3 years in a greenhouse in the Netherlands.
    \item They tested different varieties of sweet peppers and described which conditions are desireable for automatic harvesting and robotic help.
    \item Overall they authors propose a framework for an engi approach to crop design.
    \item The authors described following performance indicators which depend in the crop design: \begin{itemize}
        \item Fruit location success
        \item Detachment success
        \item Harvest success
        \item Damage rate
    \end{itemize}
    \item The proposed methodology also includes following characteristics of the crops: \begin{description}
        \item[Visibility] This is the percentage of total fruit area without occlusion
        \item[Reachability] The free space around the fruits in which the robot can freely move its manipulator.
        \item[Graspability] Measure for the quality of the pose of the fruit. "The grasping point should lie within the part of the fruit that points away from the plant stem."
        \item[Detachability] How easy it it for the manipulator to detach the fruit from the plant.
    \end{description}
    \item To modify the crops, the authors propose following methods: \
    \begin{description}
        \item[Selection of suitable varieties] The openess and fruit density highly depends on an suitable selected crop
        \item[Cultivation technique] This strongly impacts many aspects like the visibility and reachability of the fruit. Here the crops are altered by removing leaves and/or young fruits.
        \item[Climate control] \
        \begin{description}
            \item[Temperature] The authors suggest that higher temperatures in the mornings result in longer internodes and fruit stemps.
            \item[Humidity] Higher realtive humidity should also result in better characteristics: Better internodes and thus easier fruits to harvest mechanically.
            \item[$CO_2$ concentration] Higher $CO_2$ concentration should yield a decrease in leaf surface area and so an improved fruit visibility. Which then results in more harvested fruits. 
        \end{description}
        \item[Additional growing lights] Some research the authors cite, says that an higher amount of blue  light could result in more open plants with longer internodes.
    \end{description}
    \item The last category the authors suggested are the crop measures. Those allow to compare the resulting crops in perspective of the robotic harvesting. \
    \begin{description}
        \item[Crop density] This a value between 0-100\% describing how easy it is to look through the crop.  
        \item[Lenth of internodes] This describes the lenth of an segment between two leaves. A longer internode usually results in an easier approach for
         the robot and thus better harvesting. 
        \item[Position of the fruit on the stem] Since fruits hanging towards the robot are easier to harvest, this value describes the axis between the
         gripper and the fruit to harvest.
        \item[Estimation of successfull harvesting] This is an estimation based around the space around the fruits. 
        \item[Production] This is calculated based on how many fruits are harvested in $\frac{kg}{m^2}$   
    \end{description}
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors manged to create a feasible recommendation for growing sweet peppers in a greenhouse. The recommendation includes varieties of peppers, and a special cultivation method.
    \item Unfortunately climate control is not showing a positive outcome so this is not recommended because it decreases the yield.
    \item Using additional grow lights did not yield improvements for the harvestability of the crops here is additional research needed.
    \item The authors also said that it is important to deepen the research in the choosing of harvesting method.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The concrete results are not as impressive as initial thought
    \item The highly methodic approach resulting from collaboration with domain experts on the other hand is really important and should be noted.
    \item I really like the approach of engineering a optimal greenhouse and crop design for simplifying the robotic work - I will follow the authors and also deepen my research in this area.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item An in-depth methodology for describing and choosing a crop and its environment to grow it in to maximize robotic help in the whole growing process.
    \item They also have a concrete recommendation on how to culticate red and yellow peppers for optimal robotic conditions.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item They will continue to find optimal conditions for peppers and also other crops.
    \item It is also mentioned to include moving platforms in the next steps,
    \item Next to improving the greenhouse and crop conditions they want to research the effect of a smaller end-effector for grasping the produce.
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item The next step would be of course to build peppers and other crop-varieties with optimal characteristics. Would be interesting to follow the breeding and engineering of such species
    \item For me the exact definition of some of the measurements are not clear. How are exactly is the crop density calculated?
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item Engineering crops and greenhouse environments for optimal robotic help is a great idea. This will go hand in hand with designing better robots.
    \item Robots profit most from plant where the fruits are easy to recognize and grasp. This is measured in the crop density.
    \item It is also easier for robots to grasp fruits when they hang freely.
\end{itemize}

\subsection*{Summary}
Interesting and detailed case study for which crop characteristics are needed to make robots the live easier. Shocker: Its open crops with free hanging fruits! The proposed methodology is great tough!

\subsection*{Rating}
4/5



\section{Reading Report: \emph{Heterogeneous Multi-Robot System for Mapping Environmental Variables of Greenhouses}}
\cite{Roldan2016}

\subsection*{Abstract}
The productivity of greenhouses highly depends on the environmental conditions of crops,
such as temperature and humidity. The control and monitoring might need large sensor networks,
and as a consequence, mobile sensory systems might be a more suitable solution. This paper describes
the application of a heterogeneous robot team to monitor environmental variables of greenhouses.
The multi-robot system includes both ground and aerial vehicles, looking to provide flexibility
and improve performance. The multi-robot sensory system measures the temperature, humidity,
luminosity and carbon dioxide concentration in the ground and at different heights. Nevertheless,
these measurements can be complemented with other ones (e.g., the concentration of various
gases or images of crops) without a considerable effort. Additionally, this work addresses some
relevant challenges of multi-robot sensory systems, such as the mission planning and task allocation,
the guidance, navigation and control of robots in greenhouses and the coordination among ground
and aerial vehicles. This work has an eminently practical approach, and therefore, the system has
been extensively tested both in simulations and field experiments.


\subsection*{Keywords}
robotics, UGV, UAV, multi-robot, environmental monitoring, sensory system, agriculture, greenhouse


\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}
\begin{itemize} 
    \item The crop output of a greenhouse is a result of strongly controlled climate and conditions. 
    \item To keep the conditions of a greenhouse in optimal levels, high definition sensor data is needed. This allows will allow local climate control and product traceability.
    \item Equipping large-scale greenhouses with sensors to monitor data is so expensive that it is often not possible in a high spatial resolution.
    \item Instead of having multiple stationary sensors, this paper proposes to use mobile robots equipped with sensors instead.
    \item For creating a model of the greenhouse the papers proposes using following variables:\begin{description}
        \item[Input Variables]  \ 
        \begin{itemize}
            \item Ventilation system
            \item Heating system
            \item Fogging system
            \item Shading screens
        \end{itemize}
        \item[Output variables]   \ 
        \begin{itemize}
            \item Air temperature
            \item Air humidity
            \item Solar radiation
            \item ($CO_2$ concentration) not mentioned in the listing of the paper but used anyways
        \end{itemize}
        \item[External disturbances]\ 
        \begin{itemize}
            \item External Temperature
            \item External humidity
            \item Wind speed
            \item Wind direction
            \item Solar radiation
            \item External $CO_2$ concentration
            \item Cover temperature
            \item Crop temperature
            \item Soil temperature 
        \end{itemize}
    \end{description}
    \item The authors also mentioned several advantages of using wireless sensor networks for monitoring like flexibility, 
    modularity and fault tolerance. But having a mobile platform can be cheaper and even more robust then the stationary sensors. 
    And one could also use the robots for tasks like spraying and harvesting.
\end{itemize}
    \subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item The solution consists of a two robot system. One four-wheel drive unmanned ground vehicle (UGV) robot and one unmanned ground vehicle (UAV). The UAV sits on top of the ground robot until its needed.
    \item Both robots are equipped with: \begin{itemize}
        \item 2D-cameras
        \item Temperature sensor
        \item Humidity sensor
        \item Luminosity sensor
        \item $CO_2$ sensor
    \end{itemize}
    \item The goal of the duo is to drive trough the whole greenhouse using a \emph{back-and-forth} strategy.
    \item When ever the path is blocked, the UAV starts and continues to monitor the rows. UAV and UGV meet after the blocked row is monitored. 
    \item This allows the UAV to recharge and to be ready for the next blockage.
    \item Both the UGV and UAV are off-the-shelf commercially available hardware. The UAV uses a RaspberryPie for computation.
    \item In this paper, they are evaluating the strategic partnership between the two robots, \textbf{but the UAV is tele-operated!}
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The basic idea is, that the UAV can be deployed whenever the path is blocked for the UGV. A commercial greenhouse has a structured layout of rows so the team can meet up at the next crossing.
    \item Without the UAV the UGV would have to make a detour resulting in a longer runtime and more battery usage.
    \item Inside different simulated test environments the system archived a performance uplift between 8\% and 23\%.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item The idea main idea is really great and progressive. The concrete implementations are good steps in this direction but lack of real benefits.
    \item Having multiple robots patrol a greenhouse on a regular basis to get high definition spatial and lower definition temporal data has have many benefits over installing 
    a sensor grid in the same spatial dimension. Moving robots can continually measure values while moving but will measure every given point only once per round trip. Combining this
    with a couple of stationary sensors could yield in an even better modelling of the local climates.
    \item The solution from the authors is a little disappointing. On the one hand their evaluation is a result of a simulation and one small real greenhouse. On the other hand,
    the system is not autonomous. The UAV needs to be tele-operated which is a let down. I hope in future research the UAV can fly by itself.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item Build a platform from off-the-shelf hardware for mobile monitoring of temperature, humidity, luminosity and $CO_2$ concentration.
    \item The authors contribute a simulation system build in \emph{Unity3D 5.2.1} for simulating the behavior of the dual robot system. 
    \item The robot system consists of a UAV sitting on top the UGV which gets deployed as soon as the way is blocked which happends often in real world greenhouses.
    \item But they do not provide algorithms for flying the UAV. This is done manually by hand.
    \item Navigation algorithm for the UGV using SLAM and ACML.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
\begin{itemize}
    \item They want to make the UAV fly by itself
    \item Testing it in real world greenhouses is also scheduled
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item My main concern is the tele-operated drone. This has to get improved in future work: can a UAV fly properly in a cluttered and narrow environment.
    \item When having a self-flying drone, would it be better to use the combination of UAV and UGV instead of only using a UAV?
    \item How precise can one model the local climates from this kind of data? (High spatial and low temporal resolution)
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
\begin{itemize}
    \item Great idea to get critical environment data from mobile sensors, but the climate modelling aspect has to be researched even more.
    \item Heterogeneous robot cooperation is really interesting! I wish to learn more about the task and motion planning involved to get a system like this properly running.
    \item 
\end{itemize}

\subsection*{Summary}
UGV transporting a UAV for a spontaneous deployment if the path is blocked - amazing idea! The concrete implementations is a bit disappointing but good written paper anyway.

\subsection*{Rating}
3/5

\section{Reading Report: \emph{Development of a tomato harvesting robot used in greenhouse}}
\cite{Lili2017}

\subsection*{Abstract}
A tomato harvesting robot was developed in this study, which consisted of a four-wheel independent steering system,
a 5-DOF harvesting system, a navigation system, and a binocular stereo vision system.
The four-wheel independent steering system was capable of providing a low-speed steering control of the robot based on Ackerman steering geometry.
The proportional-integral-derivative (PID) algorithm was used in the laser navigation control system. The Otsu algorithm and the
elliptic template method were used for the automatic recognition of ripe tomatoes, and obstacle avoidance strategies were
proposed based on the C-space method. The maximum average absolute error between the set angle and the actual angle was
about 0.14°, and the maximum standard deviation was about 0.04°.  The laser navigation system was able to rapidly and
accurately track the path, with the deviation being less than 8 cm.  The load bearing capacity of the mechanical arm was about
1.5 kg. The success rate of the binocular vision system in the recognition of ripe tomatoes was 99.3\%.
When the distance was less than 600 mm, the positioning error was less than 10 mm.
The time needed for recognition of ripe tomatoes and pitching was about 15 s per tomato, with a success rate of about 86\%. 
This study provides some insights into the development and application of tomato harvesting robot used in the greenhouse.


\subsection*{Keywords}
tomato harvesting robot, four-wheel independent steering, automatic navigation, binocular stereo vision system,
obstacle avoidance, greenhouse

\subsection*{Questions}

\subsubsection*{What are the motivations for this work?}
\begin{itemize}
    \item Harvesting tomatoes is a very popular and labour intensive vegetable. The annual production is around 60 million tons. 
    \item Because the labor costs are rising - even in China they are trying to find a autonomous solution which can scale up.
    \item Tomatoes are very soft and sensitive vegetables so harvesting them is especially complicated.
    \item The authors name several other research in building this kind of harvesting robots, but those have slow reaction and clumsy movement. 
    \item They want to create a fast system for picking tomatoes in greenhouses
\end{itemize}
\subsubsection*{What is the proposed solution?} 
\begin{itemize}
    \item A robot system capable of : \begin{itemize}
        \item Automatic navigation
        \item Recognition of ripeness
        \item Detecting the exact position of the ripe fruits
        \item Avoiding obstacles.
    \end{itemize}
    \item The solution also contains a image recognition algorithm and a picking control method.
    \item The shown robot has a four-wheel drive with independent steering. The 4 wheels are controlled using and Ackermann steering model.
    \item It detects tomatoes using a stereo-vision camera with a resolution of 1384×1032px
    \item The pathfinding is done by using a laser scanner
    \item To pick the ripe tomatoes, the robot has a 4-DOF mechanical arm with a 1-DOF end-effector 
    \item After picking the tomatoes the robot outs them into a crate on its back.
    \item The total mass of the robot is 540 kg and it reaches an maximum speed of 3.6 km/h.
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item The authors evaluated every part of their system: \begin{itemize}
        \item The controlling of the \textbf{steering angle} resulted in an average error of 0.14° with a standard deviation of 0.04°.
        \item \textbf{Path tracking by the navigation system} could track the correct path with a deviation of less than 8cm. 
        \item They also evaluated how much weight the \textbf{mechanical arm} the \textbf{end-effector} can carry without loosing precision. When using weights up to 1kg no big
        deviation is measured. So the mechanical system is fit for its main goal of manipulating tomatoes.
        \item Inside the greenhouse the \textbf{camera-system} has to detect the tomatoes. Here the authors measured a success rate of over 99.3\% in a sample size of 300.
        \item The position of the tomatoes got detected correctly with an average positioning error of less than 10mm in a range of 600mm.
        \item Finally the \textbf{picking rate} of the robot was measured to be 87\% in a sample size of 100 tomatoes. The robot needs 15 seconds from recognition to pitching the tomatoes.
    \end{itemize}
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item This paper contains multiple system working together for a common goal. It showcases the steps needed to make the robot drive through a greenhouse and pick tomatoes.
    \item The error and performance analyses is detailed. Only thing lacking is an in-depth breakdown of the task times. The only time measurement in the paper is the 15 seconds from recognition to picking - but how long does the robot need to pick 100 tomatoes? 
    \item Tomato picking has the advantage that tomatoes are easy to detect via camera. A disadvantage is the soft nature of the fruits.
\end{itemize}
\subsubsection*{What are the contributions?}
\begin{itemize}
    \item Algorithm to track the path inside a greenhouse using laser scanner 
    \item Control architecture for the mechanical arm using a collision free A*-algorithm.
    \item Tomato detection and localisation algorithms using stereo vision
    \item In-depth error analysis.
\end{itemize}
\subsubsection*{What are the future directions of the research?} 
\begin{itemize}
    \item Improving the success rate and overall speed.
    \item Using this system to other crops.
\end{itemize}
\subsubsection*{What questions have I left?}
\begin{itemize}
    \item They left out some key metrics like time breakdown and total time needed. So I would like to know if this system is even fast enough for a commercial consideration
    \item I have not fully understand how the collision free path finding algorithm for the end-effector works, so this is something to study next.
    \item Currently the robot is only following along the space in between two rows in a greenhouse. It would be great to add additional navigation systems for a a fully automated operation.
\end{itemize}
\subsubsection*{What is my main take away from this paper?} 
\begin{itemize}
    \item The localisation in a greenhouse for tomatoes works good enough to grap them.  I did not expect for this to work that good.
    \item This paper is a good study of a holistic robot system working in the chaotic environment of a greenhouse.
\end{itemize}

\subsection*{Summary}
This paper is a good study of a holistic robot system working in the chaotic environment of a greenhouse. But some key performance indicator are missing, even some already mentioned in the introduction. 
In the motivation section of the paper they said that other systems would be too slow but did not deliver they own number. Nevertheless a good study and nice read.

\subsection*{Rating}
3/5

\section{Reading Report: \emph{Field Test of an Autonomous Cucumber Picking Robot}}
\cite{Henten2003}

\subsection*{Abstract}
At the Institute of Agricultural and Environmental Engineering (IMAG B.V.) an autonomous harvesting
robot for cucumbers was developed and tested in a greenhouse in autumn 2001. Analysis of the harvest
process had revealed that at a 2 ha Dutch production facility four robots are needed to replace the skilled
human work force during the peak season. Then assuming a success rate of 100\%, a harvest cycle might take
at most 10 s per cucumber fruit. In this paper the results of the field test of the harvesting robot are reported
and analysed in view of the performance criteria mentioned above. Cucumbers (Cucumis sativus cv. Korinda)
were grown in a high-wire cultivation system. In four independent experiments the robot was tested. The
average success rate was 74.4\%. The majority of failures originated from inaccurate positioning of the end-
effector at the stalk of the fruit. It was found to be a great advantage that the system was able to perform
several harvest attempts on a single cucumber from different harvest positions of the robot. This improved the
success rate considerably. A single successful harvest cycle took 65.2 s per cucumber. Since not all attempts
were successful, a cycle time of 124 s per harvested cucumber was measured under practical circumstances. The
test confirmed the ability to harvest more than one cucumber using a single set of images which reduced the
cycle time of a successful harvest to 56.7 and 53.0 s if two or three cucumbers were harvested. To bridge the
gap between the measured performance and the design specifications, future research focuses on improving the
success rate, faster hardware and software for image processing and motion planning as well as the reduction
of the motion time of the manipulator.


\subsection*{Keywords} Harvesting, Computer Vision, Machine Vision, Stereo Vision, Experiment

\subsection*{Questions}
\subsubsection*{What are the motivations for this work?}

\begin{itemize}
    \item The authors wanted to create a comparable solution to recent advances in harvesting tomatoes and eggplants
    \item Human labour fir harvesting is a tedious and expensive task.
    \item Robot labour needs to be able to harvest one cucumber every 10 seconds. This experiment tries to show the current (2001) limitations.
    \item Inside high-wire greenhouses mobile robots can move along tracks next to the cucumber plants which creates a somehow structured environment.
    \item This proposed architecture should allow complete autonomous harvesting.
\end{itemize}
\subsubsection*{What is the proposed solution?}
\begin{itemize}
    \item Mobile system consisting of a robotic arm having a thermal cutter and a suction cup for cutting and grabbing the cucumbers. One camera for taking two
    images (768x512px) at different positions to find 3D coordinates.
    \item They restricted the way to cucumbers could grow so that they are always in a specific range reachable for the robots manipulators.
    \item Removed leaves before hand to lessen occlusion errors.
    \item They also removed cucumbers growing too close to each other.
    \item The systems moves along a rail in 33cm steps. At each step the cameras look for cucumbers and if found and big enough proceed with the harvesting.
    \item The harvesting does not take additional images. All informations come from the initial 2 pictures. Even if multiple cucumbers are found, the initial information and processing has to be enough.
    \item Because the range of the system is around 1m, the 33cm step allow up to 3 harvest attempts for each cucumber.
\end{itemize}
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{itemize}
    \item For this experiment the authors took in-depth runtime measurements and error protocols.
    \item On average the system managed to harvest ca. 75\% of a present cucumbers. 
    \item For the whole experiment with multiple attempts and failures, the resulting harvesting time was \textbf{124s} per cucumber!!!
    \item If every first attempt would have been successful, the resulting time would have been   \textbf{75s} per harvested cucumber.
    \item Most errors (ca. 36\%) came from an misplaced end-effector resulting from poor 3D coordinates.
\end{itemize}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
\begin{itemize}
    \item Those experiments (20 years ago) have been one order of magnitude too slow for a commercial application.
    \item I like the idea of using only one camera, but the extra cost would directly result in a speed up which would basically pay for itself to use a stereo camera.
    \item The evaluation was very good. The authors managed to create an details overview over the shortcomings. 
    \item Especially the failure categorization is great. This should be an inspiration for similar failure reports for my own experiments.
    \item I was surprised that the paper was that old.
    \item 10 seconds runtime for the image analysis will be much faster nowadays.
\end{itemize}
\subsubsection*{What are the contributions?} 
\begin{itemize}
    \item This paper was a report over an in depth experiment using this harvesting system.
    \item It sheds light in many failure classes and shows how to make a proper report.
    \item The robotic system had a bad execution time and accuracy.
\end{itemize}
\subsubsection*{What are the future directions of the research?}
Harvesting crops in greenhouses will continue to be a key research topic. For this case I hope that the authors managed to increase the execution speeds.
\subsubsection*{What questions have I left?} 
\begin{itemize}
    \item Mainly the comparison to todays systems. For the my next reading report I should find a more recent paper about the same topic.
    \item If the system can easily exchange the end-effectors, it should be possible to use the mobile platform for all kind of different tasks.
\end{itemize}
\subsubsection*{What is my main take away from this paper?}
Great structured experiment with a promising setup. Having rails in a greenhouse is not too expensive and solves many navigation problems. I am looking forward to deepen my research in this area.
Would it be possible to create a rail grid with multiple robots, cooperating in this task?

\subsection*{Summary}
Definitely enjoyed the detailed reporting on different failures and execution times. This paper is an excellent blueprint on how to write a report over an experiment.


\subsection*{Rating}
4/5


\section{Reading Report: Chapter 56 \emph{Robotics in Agriculture and Forestry} from \emph{Springer Handbook of Robotics}}
\cite{Siciliano2016}

\subsection*{Abstract}
Robotics for agriculture and forestry (A\&F) represents the ultimate application of one of our
society’s latest and most advanced innovations to its most ancient and important industries.
Over the course of history, mechanization and automation increased crop output several orders of
magnitude, enabling a geometric growth in population and an increase in quality of life across
the globe. Rapid population growth and rising incomes in developing countries, however, 
require ever larger amounts of A\&F output. This chapter addresses robotics for A\&F in the form
of case studies where robotics is being success fully applied to solve well-identified problems.
With respect to plant crops, the focus is on the in-field or in-farm tasks necessary to guarantee
a quality crop and, generally speaking, end at harvest time. In the livestock domain, the focus
is on breeding and nurturing, exploiting, harvesting, and slaughtering and processing. The chapter
is organized in four main sections. The first one explains the scope, in particular, what aspects
of robotics for A\&F are dealt with in the chapter. The second one discusses the challenges and
opportunities associated with the application of robotics to A\&F. The third section is the core of
the chapter, presenting twenty case studies that showcase (mostly) mature applications of robotics
in various agricultural and forestry domains. The case studies are not meant to be comprehensive 
but instead to give the reader a general overview of how robotics has been applied to
A\&F in the last 10 years. The fourth section concludes the chapter with a discussion on specific
improvements to current technology and paths to commercialization. 



\subsection*{Keywords} Overview, Case studies, coverage planning, weed control, high precision farming, crop yield estimation,
Vehicle formation control, plant probing, leaf removal, harvesting, precision forestry, aerial based precision farming

\subsection*{Questions}

\subsubsection*{What are the motivations for this work?}
\begin{description}

    \item[Optimized Coverage for Arable Farming] \
    \begin{itemize}
        \item Minimizes soil compaction
        \item Reduces fuel cost
        \item Reduces time needed
    \end{itemize}
    \item[Weed Control] \
    \begin{itemize}
        \item Weeds directly reduce yield by competing the crops over light, water and nutrients
        \item Weed control is needed to stop them from spreading
        \item Robotic control system offer greater mechanical precision and a reduction in herbicides needed.
    \end{itemize}
    \item[High Precision Seeding] \
    \begin{itemize}
        \item When knowing the exact location of the seeded crops all following robotic operation can use this data
        \item No further local sensing is needed
        \item Can also be used as an input for localization
    \end{itemize}
    \item[Crop Yield Estimation] \
    \begin{itemize}
        \item manually gathering the required data is labour- and time-consuming error prone process.
        \item accurate estimations will help growers in labour demand forecasting. 
        \item Better planning reduces costs by optimizing packing and storage capacity.
    \end{itemize}
    \item[Precision Irrigation] Conventional irrigation technologies dent to over-watering. 
    This is of course wasteful and also increases leaching of fertilizers.
    \item[Tree Fruit Production] \
    \begin{itemize}
        \item One of the hardest problems of farming because of the complex tree geometry
        \item Sloped terrain (vineyards)
        \item Need to sense the branches
        \item Occlusion of the fruits
    \end{itemize}
    \item[Vehicle Formation control] Using multiple robots together will increase the capabilities even further. One element of MRS is to control robots in a formation.
    \item[Plant Probing] \
    \begin{itemize}
        \item Automated sample taking will enable large scale experiments.
        \item It is hard to model deformable objects like plant parts (leaves, stems, flowers, fruits)
        \item Proper models will enable individual plant part care, sampling, harvesting, predicting, robotized phenotyping
    \end{itemize} 
    \item[Cucumber Harvesting] Automated harvesting can improve efficiency and reduce labour costs. The same system can also be used to cut nonproductive leaves from the plants.

\end{description} 
\subsubsection*{What is the proposed solution?}
\begin{description}

    \item[Optimized Coverage for Arable Farming] \
    \begin{itemize}
        \item Find the optimal way to move around in complex terrain.
        \item Introduction of \emph{Optimal coverage planning algorithm}
    \end{itemize}
    \item[Weed Control]\
    \begin{itemize}
        \item A robotic system to drive autonomous over trough the fields.
        \item machine vision based approach to identify weeds
        \item precise distribution of herbicides
    \end{itemize}
    \item[High Precision Seeding]\
    \begin{itemize}
        \item a driver-less seeding system with high accuracy localization
        \item smaller wheels allow driving between ros eliminating soil compaction 
    \end{itemize}
    \item[Crop Yield Estimation]\
    \begin{itemize}
        \item A machine vision based system which is able to identify crops
        \item the system is manually driven through orchards at night and takes pictures with artificial light
        \item works for vineyards, apple orchards and strawberry ranches.
    \end{itemize} 
    \item[Precision Irrigation] A wireless sensor network monitoring the exact soil conditions.
    \item[Tree Fruit Production] \
    \begin{itemize}
        \item Proposed a family of autonomous orchard vehicles. 
        \item Only uses laser range finders, no gps for keeping the cost low
        \item Designed in a way to enable faster working human labourers.
    \end{itemize} 
    \item[Vehicle Formation control] \
    \begin{itemize}
        \item a control architecture based on a path tracking framework. 
        \item should allow multiple robots to continue to drive in formation even in ruff terrain with poor grip conditions.
        \item the system uses RTK-GPS with an accuracy of 2cm.
        \item wireless communications between robots to communicate relative positions
    \end{itemize} 
    \item[Plant Probing] \
    \begin{itemize}
        \item System consisting of a robotic arm, time-of-flight camera and a measurement technologies
        \item image segmentation and model fitting are used to find single leaves from depth informations
        \item The robot arms first finds position from where it can see the whole plant and then it moves further to enable unobstructed viewing of a single leave.
        \item After selecting a target leave it will take a probe.
    \end{itemize} 
    \item[Cucumber Harvesting] \
    \begin{itemize}
        \item Mobile platform mounted on rails in greenhouses
        \item Harvesting contains several subproblems, one of them is finding the ripeness of the crops. In this case a target weight is given. Because cucumbers are mostly water it is possible to determine the weight from 3D data.
        \item The system has a single camera but it is possible to move it around to capture the needed 3D informations.
        \item After identifying the ripe cucumber, it is cut and moved collision free to a storage crate. 
    \end{itemize} 

\end{description} 
\subsubsection*{What is the work`s evaluation of the solution?}
\begin{description}

    \item[Optimized Coverage for Arable Farming] \
    \begin{itemize}
        \item reduces turns needed ca. 15\% 
        \item reduces soil erosion cost ca. 25\%
        \item reduces skipped area cost ca. 81\%
    \end{itemize}
    \item[Weed Control] \
    \begin{itemize}
        \item 77\% of weeds got precisely eradicated
        \item reduction in herbicides
    \end{itemize}
    \item[High Precision Seeding] Not much data given, needs further study.
    \item[Crop Yield Estimation] The results show that the system works surprisingly well in a different environments.
    \item[Precision Irrigation] \
    \begin{itemize}
        \item reduces the water needed by 75\% against conventional watering        
        \item should allow multiple robots to continue to drive in formation even in ruff terrain with poor grip conditions.
    \end{itemize}
    \item[Tree Fruit Production] The different approaches followed by the original authors showed that they are twice as fast as manual labor.
    \item[Vehicle Formation control] \
    \begin{itemize}
        \item they tested using two robots, where one should follow the other in a defined distance along sloped terrain
        \item the two robots managed to stay in their path with an accuracy of 15cm
    \end{itemize}
    \item[Plant Probing] In the summary is no further evaluation. Needs additional study!
    \item[Cucumber Harvesting] \
    \begin{itemize}
        \item The system needs on average 65 seconds to cut one cucumber
        \item Success rate: ca. 75\%
    \end{itemize}

\end{description} 

\subsubsection*{What are the contributions?}
\begin{description}

    \item[Optimized Coverage for Arable Farming] Finds Optimal paths for 2D and 3D terrain with soil erosion models.
    \item[Weed Control] They presented 3 different systems to autonomously kill weeds in different scenarios. 
    The second one (volunteer potatoes in sugar beets) seemed like the best one. Further research here!
    \item[High Precision Seeding] Complete system which achieves high precision seeding.
    \item[Crop Yield Estimation] A camera rig for small tractors to gather data, can be further improved in the future.
    \item[Precision Irrigation] Wireless system for monitoring and control
    \item[Tree Fruit Production] 3 different autonomous platforms navigating by them selves inside orchards. The system has accumulated 350km driven.
    \item[Vehicle Formation control] A control architecture for two or more robots to stay in formation.
    \item[Plant Probing] Stationary system to take leave samples.
    \item[Cucumber Harvesting] Whole system harvesting cucumbers and cutting leaves. Has algorithm to determine the 
    ripeness and for finding paths for collision free manipulations.

\end{description} 

\subsubsection*{What questions have I left?}
\begin{description}

    \item[Optimized Coverage for Arable Farming] What is about the path length and exact fuel reduction?
    \item[Weed Control] How is it possible to increase the velocity further? The machines are too slow.
    \item[High Precision Seeding] Concrete implementations for further data fusion of seed map with the next scans for a living yield map.
    \item[Crop Yield Estimation] Why is the system not self driving?
    \item[Precision Irrigation] The savings in water needed and increase in growth speed are really impressive. How did this work? Did they somehow cheat on the data?
    Definitely study the original paper. 
    \item[Tree Fruit Production] Of course using vehicles is faster than manual work using ladders - but are they faster using the same approach with drivers? How does the navigation work with no GPS?
    \item[Vehicle Formation control] How valid are the results today? Driving two robots in grass does not sound to impressive.
    \item[Plant Probing] Can this system be mounted on rails?
    \item[Cucumber Harvesting] How does the accuracy shrink when speeding the process up? How fast can this scale up? 

\end{description} 


\subsection*{Summary} 
Summarizes many different papers in-depth. Refer to this for further research.

\subsection*{Rating}
5/5

\section{Reading Report: \emph{Plant detection and mapping for agricultural robots using a 3D LIDAR sensor}}
\cite{Weiss2011}

\subsection*{Abstract}

In this article, we discuss the advantages of MEMS based 3D LIDAR sensors over traditional approaches
like vision or stereo vision in the domain of agricultural robotics and compare these kinds of sensors
with typical 3D sensors used on mobile robots. Further, we present an application for such sensors. This
application deals with the detection and segmentation of plants and ground, which is one important
prerequisite to perform localization, mapping and navigation for autonomous agricultural robots. We
show the discrimination of ground and plants as well as the mapping of the plants. Experiments conducted
using the FX6 LIDAR by Nippon Signal were carried out in the simulation environment Gazebo, with
artificial maize plants in the laboratory and on a small maize field. Our results show that the tested plants
can be reliably detected and segmented from ground, despite the use of the low resolution FX6 sensor.
Further, the plants can be localized with high accuracy.


\subsection*{Keywords}
Individual plant detection, Plant mapping, 3D LIDAR sensor, Agricultural robotics


\subsection*{Questions}

\subsubsection*{What are the motivations for this work?} 
A key problem in agricultural robots is to detect and map individual plants for several reasons, including 
navigation, individual reports and individual care. For a robust plant mapping it is needed to use reliable
sensors and algorithms. Much research is done in solving this problem 
using 2D and 3D cameras but this paper on the other hand, works on detecting plants using low cost and low resolution
3D Lidar sensors. 
\subsubsection*{What is the proposed solution?}
The solution contains an algorithm for detecting individual plant in a row using a FX6 3D Lidar sensor. 
This sensor is still in development, the current version has a resolution of 29 by 59 pixel creating 15 frames per second.
To detect the plant from the resulting point cloud, the algorithm first detects the ground plane and second  
creates cluster for each plants using a k,d tree and decides for each cluster only using the bounding box dimensions.
\subsubsection*{What is the work`s evaluation of the solution?}
The proposed algorithm works seemingly fast, and manages to identify in a single frame 60\% of the plants
and using multiple frames with tracking it scores an average detection accuracy of 80-90\%. Further the average accuracy 
of the position detection is 3 centimeters. One problem occurring repeatedly is that the algorithm fails to differentiate
between the next plants if they grow into each other and the cluster connect. 

\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
The idea to use a low cost 3D sensor is quite good because, as mentioned in the paper, it works independent from 
existing lighting and is robust against fog and dust - conditions which occur frequently in the real world.
The algorithm uses only a bounding box of a cluster to determine the position of the plant. This approach works okay 
when every plant grows neatly far away from their neighbours but fails in messy real world conditions.
Some aspects are great on the other hand, it has a fast runtime, for example. I think this given approach would work 
better on a row basis and maybe use offline compute power to identify the individual plants? 
Because measuring these plants is a repeated operation, one could leverage the result of a computational more expensive
offline algorithm and map the online point cloud directly onto an existing map.
\subsubsection*{What are the contributions?}
This main contribution is an evaluation of a low-cost 3D lidar scanner with an basic point clustering algorithm in real time. besides
that they also showcase other approaches for the same problem using traditional 2D camera systems and different scanners.

\subsubsection*{What are the future directions of the research?}
The future research will include using stronger machine learning algorithms for clustering and plant separation. They also
want to work on a row detection basis.
\subsubsection*{What questions have I left?}
My main concern was the quite simple simulation model on gazebo and i hope that they improve this.
\subsubsection*{What is my main take away from this paper?}
It is possible to detect plants in real time using point clouds in the agricultural sector even with 
simple mathematical methods. The difference between a classical and those FX6 laser scanner is also interesting.
I think plant detection like this is the way to go, by improving only the algorithm it should be possible
soon to deploy at least field scouting robots in real world scenarios. 

\subsection*{Summary}
In depth paper for clustering point clouds into individual plants using a bounding box approach.
Maths is explained nicely, can be used to build something similar.

\subsection*{Rating}
4/5

\section{Reading Report: \emph{Agricultural robots for field operations: Concepts and components}}
\cite{Bechar2016}

\subsection*{Abstract}

This review investigates the research effort, developments and innovation in agricultural
robots for field operations, and the associated concepts, principles, limitations and gaps.
Robots are highly complex, consisting of different sub-systems that need to be integrated
and correctly synchronized to perform tasks perfectly as a whole and successfully transfer
the required information. Extensive research has been conducted on the application of
robots and automation to a variety of field operations, and technical feasibility has been
widely demonstrated. Agricultural robots for field operations must be able to operate in
unstructured agricultural environments with the same quality of work achieved by cur-
rent methods and means. To assimilate robotic systems, technologies must be developed
to overcome continuously changing conditions and variability in produce and environ-
ments. Intelligent systems are needed for successful task performance in such environ-
ments. The robotic system must be cost-effective, while being inherently safe and
reliabled human safety, and preservation of the environment, the crop and the machinery
are mandatory. Despite much progress in recent years, in most cases the technology is not
yet commercially available. Information-acquisition systems, including sensors, fusion
algorithms and data analysis, need to be adjusted to the dynamic conditions of un-
structured agricultural environments. Intensive research is needed on integrating human
operators into the system control loop for increased system performance and reliability.
System sizes should be reduced while improving the integration of all parts and com-
ponents. For robots to perform in agricultural environments and execute agricultural
tasks, research must focus on: fusing complementary sensors for adequate localisation
and sensing abilities, developing simple manipulators for each agricultural task, devel-
oping path planning, navigation and guidance algorithms suited to environments besides
open fields and known a-priori, and integrating human operators in this complex and
highly dynamic situation.


\subsection*{Keywords}
Agricultural robots, Robotics, Field operations, Autonomous


\subsection*{Questions}

\subsubsection*{What are the motivations for this work?}
The main subject of this paper is to show the current development, ideas and problems in the field of agricultural 
robotics. This review paper explains first the background, then the economic feasibility and furthers goes into 
concepts, principles and components.
\subsubsection*{What is the proposed solution?} 
The paper concludes, that with current technologies the broad usage in commercial farming is not possible yet and 
proposes to focus research on a number of fields. Those fields include sensor fusion for better localisation, 
engineering of better simple manipulators and the development of specific path planning, navigation and guidance algorithms
for agriculture.
\subsubsection*{What is the work`s evaluation of the solution?}
This question is not applicable.
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
The authors make a great job in displaying the current technologies and their limitations. With this knowledge it is 
easy to identify a subproblem to work on.
\subsubsection*{What are the contributions?}
Several points come to the mind. Firstly they create an in-depth background needed to understand the need of automated
systems in agriculture, but also explain why it is so hard to create such systems. 
They propose a categorization of robotic system after the structure of their environment and object of interest. Both 
can be either structured or unstructured. This categorization creates four different categories. First, a structured 
environment and a structured object: This is the industrial domain. Second, a strucutred environment and a unstructured
object: the medial domain. Further there is the unstructured enviroment with a structured object: the military, space, underwater
and mining domains. The last domain, unstructured in environment and object of interest is the agricultural domain.

The next contribution are guidelines under which circumstances a robot can be commercially successful. These guideline conclude
that it is possible to start using robots even if the costs are the same as conventional methods if the work of
the robots create more steady and predictable processes.

A big part of the review are categorization concepts, components and principles. These include Human-Robot-Systems versus
Autonomous Robot Systems. In the component section the authors underline following topics: steering and mobility, 
sensing and self-localization, path planning and guidance and last but not least, manipulators and effectors.
\subsubsection*{What are the future directions of the research?}
This question is not applicable.
\subsubsection*{What questions have I left?}
Many questions, this paper is an excellent basis for further research.
\subsubsection*{What is my main take away from this paper?}
One of the main problems is the highly dynamic environment and the need to react fast to unprecedented situations.
This creates the question on how to define behavior in such a way to allow and strengthen the capabilities of 
improvisation.
\subsection*{Summary}
In-depth review paper with some self citations but besides that it gives many new points to deepen my reseach.

\subsection*{Rating}
5/5

\section{Reading Report: \emph{Agricultural robots—system analysis and economic feasibility}}
\cite{Pedersen2006}

\subsection*{Abstract}
This  paper focuses  on  the  economic  feasibility of  applying  autonomous robotic  vehicles  compared  to  conventional  systems  in  three  different  applications: robotic weeding in high value crops (particularly sugar beet), crop scouting in cereals and grass cutting on golf courses. The comparison was based on a systems analysis and an individual economic feasibility study for each of the three applications. The results  showed  that  in  all  three  scenarios,  the  robotic  applications  are  more  economically feasible than the conventional systems. The high cost of real time kinematics Global Positioning System (RTK-GPS) and the small capacity of the vehicles are the main parameters that increase the cost of the robotic systems.

\subsection*{Keywords}
Agricultural robots, Grass cutter, Autonomous vehicles, Economics, Feasibility study, Robotic weeding, Crop scouting

\subsection*{Questions}

\subsubsection*{What are the motivations for this work?}
The papers main focus lies on displaying the cost reduction possible by utilizing 
autonomous system for agriculture tasks. Most agricultural task can not use individual-plant-based solutions with
conventional methods. By using robots and big data processing it will be possible to care for each plant individually.
Taking care of an identified weed patch for example will need much less herbicides than spaying the whole field preemptively.
\subsubsection*{What is the proposed solution?}
The authors propose solutions for using autonomous robots for field scouting - the identification and localisation 
of growing weeds -, intra-row and near-crop weeding and automated grass cutting. 
\subsubsection*{What is the work`s evaluation of the solution?}
In all scenarios the authors showcase a reduction in primary and secondary costs in comparison to conventional methods.
\begin{description}
    \item[Field scouting] 20\% cost reduction in labor and secondary benefits of the data because it is now possible to only deploy herbicides where needed.
    \item[Weeding] Only by reducing the cost of the navigation system by half it is possible to save 12-21\% or manuel costs. and reduction of herbicide use of 90\%   
    \item[Grass cutting] Reduction of cost of 52\% (but only when paying the gardener 27 Euro per hour, lol) 
\end{description}
\subsubsection*{What is my analysis of the identified problem, idea and evaluation?}
The usage of automated systems for growing crops is one of the key points in reducing the environmental footprint
of large scale agriculture. The three analyzed areas are great entry points for deploying such systems. Especially 
the field scouting and the automated weeding are very interesting. For the evaluation the authors compared 
the costs of the components with average conventional costs witch is mostly reasonable, expect the estimated
labor cost of the gardener of 27 Euros per hour for grass cutting.
\subsubsection*{What are the contributions?}
The ideas of the authors in breaking down the cost of the robots into several components are very helpful to estimate economic costs of different system for
this usage. The main contribution is this economic analysis which helped to spark more research in this direction.
\subsubsection*{What are the future directions of the research?}
There will always be economic analyses for newer technology.  
\subsubsection*{What questions have I left?}
Because this paper is from 2006 I am eager to find a similar, more current breakdown.
\subsubsection*{What is my main take away from this paper?}
That it is feasible to automate many agricultural tasks with almost existing technology.

\subsection*{Summary}
Great in depth analysis but dated (2006), has good numbers for conventional cost estimates.
\subsection*{Rating}
3/5


\newpage
\bibliography{isw_research}
\bibliographystyle{apacite}

\end{document}
